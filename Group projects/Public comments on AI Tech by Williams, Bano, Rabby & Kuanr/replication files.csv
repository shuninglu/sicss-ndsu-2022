document.id,commentID,commentTitle,commentText,..JSON
1,DHS-2021-0015-0213,Comment Submitted by Yahaya Tabsum,"I believe that humanity and specifically Americans can benefit from AI. However, the way it&#39;s currently being deployed, it WILL do more harm than good. Current AI is closed-source, used for nefarious purposes, and helps people at the expense of their privacy.<br/><br/>I believe AI should be open-sourced. I believe that an easy kill switch should be implemented, that is impossible to remove. That way, if anyone starts using AI for harmful reasons, it can easily be shut down. The kill switch should use some specialized equipment, that is priced enough for individuals to not be able to obtain it, and for governments and humanitarian organizations to be able to use it.<br/><br/>Open sourcing AI helps protect our 1st amendment, so that we may be able to keep our glorious constitution at it&#39;s peak, even when emerging into the era of AI. Development of AI should also be easily accessible to anyone (maybe introduce HS and College/University courses?), so that we can ensure that great young minds can help perpetuate the progress of good AI.<br/><br/>Now, about facial recognition. I am not a huge fan of it, but I understand it&#39;s need in some areas. So I ask that a universal data conduct be applied. Facial recognition data can only be held for 30 days, and hashed versions can be kept for 1 year. I fear that facial recognition data (and other data for the matter) may be easily utilized by branches of the government, under that multiple acts that allow so. I hope that clear Terms and Conditions can be made available (Less than 10 pages please), so that each citizen of our prosperous and great nation may understand what they are surrendering.<br/><br/>I know that it is likely that my advice will not be heard. But I hope, that one day, we may live in a semi-utopia, where everyone can be assisted (That&#39;s right, assisted. Please don&#39;t replace entire sections of things with AI, always keep a human on watch. Or maybe a few. Maintain a 3:1 ratio, at least. That&#39;s AI:Human BTW.) with AI, without sacrificing their God-given right, the freedom of thought and speech.<br/><br/>(Usually I remain Anonymous for posts like these, but I felt it was too important and needed a real human name behind it.)<br/><br/>Thank you for reading.<br/><br/>God bless you,<br/><br/>-Yahaya .T",
1,DHS-2021-0015-0215,Comment Submitted by Anonymous,"No, thank you.",
1,DHS-2021-0015-0224,Comment Submitted by Anonymous," you wish to build a world where the individual has no rights in the name of security, one who gives up liberty for the sake of security deserves neither. You all are what the founding fathers warned us about.",
1,DHS-2021-0015-0217,Comment Submitted by Anonymous,"Well, this is one of the more ridiculous ideas I&#39;ve heard come out of the Federal government this year.<br/><br/>I have personally been a victim of this so-called &quot;emerging technology&quot; while leaving the United States, and despite the clear indications that citizens have the ability to opt out, I was ultimately told by law enforcement to submit to the scans or miss my flight. So, even before this is rolled out en masse, the government has shown a willingness to ignore its own laws designed to protect individuals from this sort of overreach. This does not exactly do much to garner faith in the system.<br/><br/>Additionally, governments across the world (and the US Federal government is no exception here) have repeatedly shown that they are not good or effective stewards of personal data, as evidenced by the repeated mass loss or leaks of even the most sensitive of personal data. How many news articles have I read about the government losing hard disks with, for example, employee or &quot;customer&quot; files for large government agencies? Too many to even remember, and certainly too many to count. Given that the government cannot be trusted with this sort of data, and it&#39;s clear that the only way to protect the aforementioned data is never to collect it in the first place, this by itself should be enough to kill this ridiculous idea.<br/><br/>Now, we can approach the subject of &quot;machine learning&quot; or &quot;artificial intelligence&quot; which, speaking as someone who has some experience in this matter, is a complete farce. Current facial recognition software is easily fooled by something as simple as growing or shaving a beard, wearing glasses, or even clothing with something that resembles enough of a face to fool the computer. The age-old trick of &quot;hold a photocopy up to the camera&quot; comes to mind, and those tactics still work on every facial recognition software library I have encountered. These systems have also been proven to adopt the biases of whichever humans originally programmed or trained the algorithm, which is not a problem that can be solved technologically.<br/><br/>There also exists numerous issues regarding the distribution of software onto whichever devices that the government plans to use for this purpose. Even if government were willing to obey its own rules with regards to data retention policies and secure deletion, there is the matter of trust in the software itself, which is often created by outside organizations or contractors. While we can pretend to mitigate some of these concerns by making the software open source and subject to public scrutiny, there currently exists no technological solution that can guarantee to the subjects of this software (i.e. people with faces) that the software published and scrutinized publicly is actually the software running on the device during routine operation. This causes multiple issues, as compromised devices can transmit photos and metadata to places where data retention policies can be easily violated, to foreign adversaries, or to anyone else with an interest in collecting face data.<br/><br/>With regard to hardware, the past few years have made it abundantly clear that the United States currently lacks the facility to actually manufacture all of the components required for a deployment of this scale. As we have seen from various news articles in the past, adversaries have the ability to embed rogue chips into their hardware which are nearly impossible to detect without sophisticated scanning technology and expertise to actually run the scanners. Combined with the fact that nearly every device on the planet now has the capability to access remote systems (and it is to be assumed that these devices would retain connectivity for management and update purposes), it is similary impossible to guarantee data protection even at the hardware level.<br/><br/>Finally, there is the issue of trust in TSA and DHS on their own merits. These agencies were created as a knee-jerk reaction to the events of September 11, 2001, and quickly became two of the most hated government agencies due to repeated cases of harassment of both transport passengers and non-passengers, a seemingly-overwhelming desire for agency heads to flex the power of their organizations, and the petty tyranny displayed by many agents employed by these fundamentally-inefficient government jobs programs. Indeed, many tests have determined that the &quot;old way&quot; was superior in nearly every way, from the actual ability to detect contraband, to passenger satisfaction with screening processes. Additionally, some of the employees of these agencies do not seem to have been vetted very carefully and seem to be unwilling to make decisions on their own. I do not want to think about what happens when agents are given blanket permission to harass and detain others because a computer said so.<br/><br/>Anonymous for obvious reasons.",
1,DHS-2021-0015-0220,Comment Submitted by Anonymous,"The proposed request regarding the Department of Homeland Security&rsquo;s utilization of artificial intelligence or facial recognition when dealing with customs and border protection, transportation security, and investigations would likely have a negative impact on the LGBTQ community. LGBTQ members play a prominent role in the United States and are especially at risk for bias, privacy, and security concerns brought on by facial recognition. <br/><br/>As the Supreme Court determined in Katz v. United States, an individual has a constitutionally protected right of privacy in their own person.  This standard is measured by whether or not the individual has an expectation of privacy and whether the expectation is one that society considers to be reasonable.  <br/><br/>Moreover, in United States v. Antoine Jones, the Court further solidified an individual&rsquo;s right to privacy in their own person, while moving about in public places.  The Court determined that law enforcement must have consent or a valid warrant to track an individual&rsquo;s movements over a period of time. By utilizing advances in technology (a GPS tracker), the subject was deprived of their constitutional right to privacy.  The Court expected law enforcement to go through the same motions necessary to obtain detailed tracking information of subjects as it would have decades before without advanced technology. <br/><br/>Here, the Department of Homeland Security should be barred from utilizing facial recognition to gain advantages it would not have, absent advanced technology. LGBTQ members, like others, have an expectation that the government will not be tracking, storing, and potentially sharing their daily activities as they move through society. This expectation is one which American society would consider to be reasonable. This tracking infringes on an individual&rsquo;s constitutional rights to privacy in their own person and rights to be free from unwarranted search and seizure. Artificial intelligence and facial recognition have been shown to &ldquo;misgender trans people and inherently discriminate[s] against non-binary people.&rdquo;  <br/><br/>Moreover, facial recognition enables the government to track LGBTQ members throughout their daily lives. By recording some of their most private moments&mdash;which can be combined to infer all kinds of sensitive data points&mdash;members are at risk of government profiling. The government could use facial recognition to combine members&rsquo; activities across multiple channels and from various places to construct and share personal profiles amongst various entities. In States where discrimination is still legal against LGBTQ members, sensitive inferences about sexuality can have drastic effects on one&rsquo;s employment status, housing, social environment, and other areas of everyday life.<br/><br/> If any personal information gained through facial recognition would be available to the public under FOIA, this disclosure should be prohibited.<br/><br/>Thus, the utilization of facial recognition is not necessary. The Department of Homeland Security should be required to go through the proper channels by obtaining consent or a warrant before it can track an individual&rsquo;s every move throughout society.<br/>Therefore, I oppose the utilization of facial recognition technology in any capacity<br/><br/>Question 5:<br/><br/>I oppose utilizing automated collection techniques or the use of other forms of information technology if the technology includes planting cookies on the unsuspecting respondent&rsquo;s electronic devices. By utilizing third-party applications, it is highly likely the application makes money by planting surveillance cookies on the user&rsquo;s device. Thus, an LGBTQ member could be subject to illicit surveillance from the third party for all kinds of personal and sensitive data.<br/><br/>This use of third-party applications and cookies can have an extra traumatizing affect on the LGBTQ community. LGBTQ members often suffer discrimination, which leads many to hide their sexual orientation. By allowing surveillance tracking cookies, such as Google Analytics, the government may inadvertently lead to the disclosure of one&rsquo;s sexual identity. For example, the Regulations.gov website attempted to plant a Google Analytics cookie onto this internet browser on December 4, 2021.<br/><br/>A potential solution to this challenge would be for the government to create its own technology platform that does not plant any cookies on the user&rsquo;s device and to refrain from utilizing Google Analytics. Perhaps this type of platform already exists or could be created and utilized for a variety of programs.<br/><br/>In summary, I oppose the use of automated collection techniques or other surveillance forms of information technology. Modifications to improve this proposal, as noted above, are likely to greatly improve the potential impact on any LGBTQ community members who may become involved.<br/>",
1,DHS-2021-0015-0222,Comment Submitted by WOPLLI Technologies,"It is true that Artificial Intelligence and in particular Facial Recognition technologies are controversial. 
Technology by itself is progressive but its application which is based on a scenario can cause issues 
related to privacy, security, and bias for people. This in turn can lead to loss of Trust in technology & in 
social systems.
As a Trust building measure, DHS (and other organizations in both public & private) should consider 
publishing publicly available data showing KPIs (Key Performance Indicator) implementation of AI 
(+facial recognition) via independent bodies.
(1) Data shared by DHS with other entities
(2) Collected data used for other purposes than initially intended (and consented)
(3) Percent of false positives
Further, DHS should consider
(1) Improving technology maturity without testing on live people.
(2) Create Governance on how AI decisions would be handled, especially if they are negative. Put 
humans in the loop.
(3) Create processes with 3rd party assessments.
(4) Improve privacy management with better consent and control for people.
(5) Improve security by improving [digital / IT] architecture.
Following are few issues –
A. Technology Maturity and automated decisioning
A. Facial recognition techniques are not mature enough at this point. They have been found to 
have false positives based on race of a person, but there could be other factors such as age, 
gender etc. Researchers have found that leading facial recognition algorithms have different 
accuracy rates for different demographic groups. The first study to demonstrate this result was a 
2003 report by the National Institute of Standards and Technology (NIST). More studies have 
been done including one by researchers from MIT and Microsoft in 2018 showing that gender 
classification algorithms—which are related, though distinct from face identification 
algorithms—had error rates of just 1% for white men, but almost 35% for dark-skinned women. 
Through their thorough testing in 2019, NIST also confirmed that a majority of algorithms exhibit 
demographic differences in both false negative rates (rejecting a correct match) and false 
positive rates (matching to the wrong person).
B. When facial recognition data is used in combination with other data (that may be private or 
public data) such as emotions, expressions, connections in social media etc. there are more 
chances of a false positive.
With this -
• At worst a wrong person may get identified and their profile might be filled with wrong 
information. 
• Better but still bad, right person may get identified however their (other) information may be 
mis-interpreted when connected to the profile.
• At best, right person may get identified and connected with their correct (and complete) 
information leading to right interpretations.
For above cases, and depending on who is analyzing and taking action, and what kind of action it is; it 
can jeopardize some one’s life, if they happen to either in #1 or #2. With today’s technology maturity 
levels, it is more likely to happen.
Further, if AI algorithms are put in place to take actions automatically without recourse (to humans or 
for appeal), it can be worse. Hence, there needs to be a human in the loop to make and execute on a 
decision. Responsibility of decisions (especially negative decision) should be with humans.
Other notes:
Note 1 - In totalitarian regimes or autocratic organizations, where the recourse to correct information or challenge 
can be limited, these issues can cause havoc in someone's life.
Note 2 - If decisions are made to allow, disallow access to places by private parties (like social media, public places 
etc.), it could lead to bias.
Note 3 - If life affecting decisions are made (such as police action, law enforcement, legal decisions etc.) 
automatically, it can be a biased decision to begin with due to the data sets / maturity level & if there is no human 
involvement or no recourse for the person, it can lead to life altering situation for a person.
Recommendation:
1. Increase maturity of the technology & processes, without testing on live people.
2. Be aware of the potential negative affects on people if there is a negative decision. Form 
alternate processes to bring humans in loop in such scenarios for decision making.
a. Put humans in the decision-making loop. At the minimum when there is a negative 
result.
3. Use more diverse datasets for training.
4. Setup end to end governance.
5. Be transparent with false positives KPIs etc.
B. Insufficient Privacy measures available today
Privacy means that 'the parties to a conversation are only known by the parties to that conversation'. 
In case of a picture or video, there is no ‘literal conversation’ so it comes down to consent and the 
situation of how the interaction happens between the subject (person) and the party collecting & 
processing data. 
In some scenarios, pictures could be taken (or collected) with awareness of the person however person 
is still not aware how and where the data would be processed. Examples are - (a) one party takes picture 
of the other as a single subject or part of the group using a visible camera (b) A person uploads their 
picture to a website or a platform. (c) A camera takes picture in private place and property (such home 
& vicinity, church etc.). 
In all these cases, it is possible to take the picture and share further and people are mostly not aware.
Hence, there should be controls in three places -
1. A person's consent (or control) should be required to take the picture. For (c), a notice should be 
required by the property owner.
2. A person's consent (or control) should be required to share the picture further. Limited parties 
for sharing and time constraints should be defined.
3. A person's consent (or control) should be required for use of the picture (such as for data set 
formation for AI algorithm and Machine Learning). Use should be limited to the scenario for 
which the consent was given.
In other scenarios, information (picture or video) could be taken while the person is not aware of its 
existence or how the information will be used. Examples are - (a) A camera takes pictures in an open 
public place (such as street, grounds etc.) while the person is walking & unaware (b) Another party takes
information (picture data) from what is considered as a public location (such as social media sites) and 
combines with other forms of information to produce different results. (c) Use of stealth cameras (such 
as in Glasses or other hidden places)
In (a) above, in wrong hands, the information collection & corresponding situation can lead to one-sided
mass surveillance. 
In (b) above, there is no connection between the person and the 3rd party processing the information, 
which could lead to mass data processing without consent.
In (c) above, a person may not be aware that they are being recorded and where that information will 
end up and get processed.
In either case, there should be a way for a person to give consent (to take the picture, share the picture 
& use the picture). 
Mass surveillance and mass processing by 3rd parties should be reduced or removed for use in AI 
applications. This was recently cited by UNESCO agreement (all 193 member countries) where they 
called for better privacy & banning mass surveillance - UNESCO member states adopt the first ever 
global agreement on the Ethics of Artificial Intelligence
We must devise other ways to track potential bad actors or terrorist activities while maintaining civil 
liberties (& right to their privacy and data) for people. Technology that allows for stealth recording 
(without consent) either by Government or private parties should be discouraged and disallowed. This 
could lead to other problems beyond a simple privacy breach. 
Recommendations:
1. Implement ways for a person to control their data (including facial recognition) usage. This is 
better than consent, but at the minimum implement consent techniques for different stages.
2. Implement data collection and data processing minimization of people.
3. Ban mass surveillance.
4. Minimize stealth and hidden use of camera technology.
5. Use decentralized architectures for identity & identifier management.
6. Be transparent with how and where person’s data was used (with public KPIs)
C. Insufficient Security leading to breaches
It is important that the data (including facial recognition data) is secured. Depending on AI and how it is 
applied, there are 3 areas (below) where data needs to be secured at the highest level.
In general, given various recent data breaches, the current [digital / IT] architectures are not sufficient. 
Different architectures should be evolved and considered. 
1. Data sets, so that data used to train AI does not get corrupted. Data set that is not governed and 
mitigated for bias / ethics issues can result in untoward results from AI.
2. AI / human interface. If information is being passed between AI and human; that exchange 
interface should lead to secure data transfer.
3. Execution / run time of AI. When AI is executing, making automated decisions, that information 
exchange needs to be secure with integrity maintained.
Recommendations:
1. Evolve new standards for more secure architecture that is decentralized and distributed.
2. Be transparent with data breach events",
1,DHS-2021-0015-0188,Comment Submitted by Anonymous,"Lets be real you are going to do this whether anyone says not to. You will gladly say its to &quot;protect&quot; everyone which is what you use to push every agenda nowadays. When in reality it will end up in the hands of corporate agendas to make money since that&#39;s who gets all these politicians elected anyways.<br/><br/>So no you shouldn&#39;t use AI and facial recognition EVER. Life is dangerous, life is not safe and freedom will always come with risk. So don&#39;t go on about stealing everyone&#39;s face and saying its for the betterment of society.",
1,DHS-2021-0015-0185,Comment Submitted by Killian Holt,I worry that incorporating AI facial recognition software on such a large scale will run into the issue of a bias forming that would lead to someone being arrested for a supposed crime they would commit. Which completely spits in the face of our legal system of &#39;innocent until proven guilty&#39;,
1,DHS-2021-0015-0187,Comment Submitted by Rebecca Taylor,"I do not agree with the DHS&#39; use of artificial intelligence and facial recognition technology- I think it is invasive, biased and irresponsible. Full stop.",
1,DHS-2021-0015-0197,Comment Submitted by Anonymous,"Facial recognition is a severe violation of our privacy, especially when AI is involved. There needs to be major regulations preventing its misuse, especially concerning surveillance agencies.",
1,DHS-2021-0015-0199,Comment Submitted by Anonymous,Disgusting abuse of our rights and freedoms. Just another way for you to control the population huh.,
1,DHS-2021-0015-0202,Comment Submitted by Joel De la Rosa,I personally feel that the use of this technology is a violation of multiple constitutional rights and has an extremely high potential for misuse and abuse. I am against the use of this emerging technology.  ,
1,DHS-2021-0015-0206,Comment Submitted by Anonymous,I believe that facial recognition is dangerous and a privacy nightmare. I don&#39;t believe the pros out weigh the cons.,
1,DHS-2021-0015-0203,Comment Submitted by Matt Pike,"Before we start, i understand the appeal of AI as a way to automate processes and the use of Facial recognition to identify people of interests but this technology can result in miss-identification and abuse and must be regulated and used appropriately.<br/><br/>The software running the facial recognition algorithm can make mistakes due to a number of reasons. Lighting, image quality, or just being a poor algorithm. These mistakes can not only lead to people of interests slipping by but random people being mistaken as people of interests. These mistakes can lead to panic when there isn&#39;t a need for any, imprisonment when it isn&#39;t necessary, and deaths that were uncalled for. Any use of the technology must be accurate and can not be considered &#39;all knowing&#39; as this trust in faulty software will cause accidents, incidents, lawsuits, and deaths.<br/><br/>The facial recognition software must also be regulated. While anyone could look up a tutorial on how to write and teach a facial recognition program in python they lack the massive repositories of data that can be used to teach the recognition software. The public should be aware of how these systems work, how they are used in day to day practice, and their accuracy with actual numbers and data to compare to. The regulating body should be aware of the amount of data that went into creating these algorithms.<br/><br/>I understand the use of automation in all workplaces, not just in the various agencies, but would like to stress the need to review the information given by these systems and the information put into it.<br/><br/>Computers make significantly fewer mistakes then people but the mistakes people make will ensure the computer make a mistake. Garbage in garbage out. If a user makes a mistake then the information they gathered will be wrong. Another person should be able to gather the same information as the first. With that information received, someone needs to be able to look at the information gathered and be able to ensure it is accurate and makes sense. A person who lives and never left California identified as a suspect in New York dose not make sense and should have the system reviewed.<br/><br/>On that note, an office in the state should not have access to a federal facial recognition data set unless the investigation in question crosses state lines. They should have access to their own local facial recognition data set and the public made aware of it and its accuracy. <br/><br/>I know the US won&#39;t be the only country developing this technology but we should take precedent in what we allow with this technology.",
1,DHS-2021-0015-0028,Comment Submitted by Anonymous,I feel that there is a major concern about using this for racial and religious profiling more than anything else. There is no way to &lsquo;train&rsquo; the system to not choose a random guy at the airport for patdowns just because he is brown and has a beard.<br/><br/>AI deployment needs to be regulated and passed through an act of congress after being debated on.<br/><br/>This website is unknown to most people so not many people who are experts in the field of AI may be able to comment on it.,
1,DHS-2021-0015-0030,Comment Submitted by Anonymous,"Absolutely not. There&#39;s too much government overreach and surveillance these days already. Electronic data is captured at an incredible, likely unconstitutional rate. We have rights. ",
1,DHS-2021-0015-0038,Comment Submitted by Corey Nelson,"The fact that a form of surveillance such as this has shown false positives in other nations that have used it most likely reason enough not to use it in our own.  It also has the greater potential to be used/hacked by other nations to surveil our own citizens.  I do not want to live in a surveillance state where we feel we are being watched at all times, whether it&#39;s by my own government, or another government that has hacked our sad state of tech in the USA.  We have other projects that would actually help our citizens out, but instead we come up with ideas like this.  What a waste of our taxes and resources.",
1,DHS-2021-0015-0031,Comment Submitted by Sean Argyle,"I am generally opposed to the use of AI by law enforcement agencies specifically, and I am highly skeptical of the use of AI by other organizations both governmental and private.  My concerns fall into three main categories based on the the ubiquitous presence of cell phone location tracking, facial recognition, license plate scanners, genetic information databases, gait analysis, and social media monitoring (just to name a few) collectively.<br/><br/>One, these technologies serve as chilling effects and undue burden upon a citizen&#39;s First Amendment rights in all it&#39;s forms be it religion, expression, assembly, or the right to petition.  For example, a Muslim living in a predominantly Christian part of the country may have to go to great lengths to avoid having their Constitutionally-protected attendance at a Mosque be tracked.  At a minimum, this may include leaving cell phones at home, walking rather than using a car, covering one&#39;s face, and wearing mismatched shoes to alter their gait.  This concern is only redoubled due to the massive and frequent leaks of governmental data such as the Office of Management and Budget leak in 2015 or the DC Police leak in 2021.<br/><br/>Two, these technologies can be functionally equivalent to surveillance devices such as ankle trackers that have historically been reserved for convicted criminals.  That is to say, I believe that these technologies represent a violation of a citizen&#39;s Fourth Amendment right to be secure in our persons, houses, papers and effects.  This violation is redoubled by the so-called &quot;third party doctrine&quot; that means an unsent email containing a photograph of my face sitting in my Gmail drafts does not have the same protections as an unsent letter containing a physical photograph of my face sitting on my desk.<br/><br/>Three, these technologies often rely on algorithms that are not made available to the public and are even sometimes proprietary.  This is a violation of Fifth and Sixth Amendment rights of the accused.  Research into these algorithms has historically been actively prevented, meaning that people do not have full access to information regarding how they came to be accused.  Moreover, there is increasing evidence that these tools are subject to all manner of error due to system limitations (such as cameras struggling with darker skin tones) and training bias (such as using existing conviction data that is known to have systemic, structural bias against minorities).  <br/><br/>I request that the government issue a moratorium on all law enforcement use of AI and that all private use of AI must be opt-in rather than opt-out with simple and easy requests for removal of personal data from data sets.  Furthermore, non-consensual data gathering, &quot;scraping,&quot; or sale of data should be considered a criminal act, and terms of service that strive to force consent should be considered unconscionable contracts of adhesion.<br/>",
1,DHS-2021-0015-0051,Comment Submitted by Anonymous,"Facial Recognition is a technology which is too unreliable to use on a government scale, frequently misidentifying people, especially women and people of color. Using such technology will cause many innocent people to be falsely accused, not to mention violate their basic human right to privacy.<br/><br/>It has also been shown that implementing technology like this does not actually help prevent crime. All you are doing is harming the rights of law-abiding citizens, while criminals will use more and more advanced methods to get around the tech and continue doing crime.",
1,DHS-2021-0015-0053,Comment Submitted by Alan Trevino,"While technology is expanding and evolving at a rapid rate, I do not agree with an artificial intelligence (AI) program making facial recognition scans to look for people.<br/><br/>I do not believe Artificial Intelligence technology has been refined enough.  Additionally, I do not trust the companies that are making efforts in Articial Intelligence.",
1,DHS-2021-0015-0058,Comment Submitted by Anonymous,I&#39;ll have none of that spying nonsense under any circumstance please and thank you<br/>,
1,DHS-2021-0015-0071,Comment Submitted by Devin Prince,"The use of facial recognition technology by large and powerful agents such as the US government (and large corporations) should be barred in it&#39;s entirety. There is a great deal more harm that can be done using this technology in such a casual and widespread manner that is being proposed than there is good. Each and every law abiding United States citizen should not be placed under constant fear and anxiety from their own government knowing their every move, simply to gain a little security. This technology, when used by government actors, is the first major step towards a tyrannical police-state.<br/><br/>Many of the freedoms we gave up in the PATRIOT act have not shown to have provided the increases in security that were promised.<br/><br/>The TSA regularly gropes innocent passengers and makes law-abiding US citizens go through unnecessary grief simply for travelling, yet statistically speaking, the amount of crime they prevent is minimal at best. The data they collect, however, can be mishandled and abused.<br/><br/>I had the liberty of growing up in an era where &quot;privacy&quot; was still a concept that was reasonably well-understood. The youth of today has given up on this in large part due to the lack of protections of their privacy when interacting online. We should not make this worse just because it is &quot;socially acceptable&quot; or &quot;the norm.&quot;<br/><br/>I implore you, please do everything in your power to prevent widespread use of facial recognition AI by the US government, including via third party vendors (e.g. Microsoft, Google, Meta, or any of the other companies doing government contracts to make these services behind closed doors).",
1,DHS-2021-0015-0088,Comment Submitted by Joseph Reichert,Highly disagree with the use of this technology and the surveillance state.,
1,DHS-2021-0015-0034,Comment Submitted by Keith Novak,"(1) Is this collection necessary to the proper functions of the Department? - No <br/><br/>(5) how might the Department minimize the burden of this collection on the respondents, including through the use of information technology? - By not collecting this information on US citizens in the first place.",
1,DHS-2021-0015-0046,Comment Submitted by Jake Imholte,AI and Facial Recognition is a massive overreach and an invasion of privacy. It is discriminatory and scary that you are even considering it. It will not help to prevent any crime and it will only violate civil liberties. Please do not use this technology. ,
1,DHS-2021-0015-0049,Comment Submitted by Jared Milbee,"Facial recognition is completely unnecessary, a waste of public funds, and easily could be abused for unintended purposes. We shouldn&#39;t be using it or creating a system for it.",
1,DHS-2021-0015-0063,Comment Submitted by Gideon Smith,"This is disgusting and a clear breach of basic human rights, and our American constitutional right to privacy.",
1,DHS-2021-0015-0077,Comment Submitted by Anonymous,"In regards to the usage of facial recognition: I think that so long as the technology is only utilized in areas in which there is no reasonable expectation of privacy, then there isn&#39;t necessarily an issue with it. In other words, should the technology be deployed for surveilling thing such as personal webcams, for example, this would be a gross violation of privacy. Additionally, the technology should only be used for detection of matches in order to better facilitate a particular search, but *never* used as de facto evidence of a match in and of itself. If a facial recognition match puts someone at a particular place at a particular time, for example, this should never be sufficient evidence so as to assert that as fact. In contrast, should a wanted criminal have their face flagged in a mall, and this triggers the investigation to go pursue it at that location, this would be an appropriate usage of the technology.<br/><br/>In regards to the usage of AI in general, my problem comes with the debates I&#39;ve seen regarding the appropriate classification parameters that should be fed into networks. Parameters should always be as specifically consequential to the decision as possible, and should never fall back on &quot;proxy&quot; parameters for making decisions. For example, take something like the decision regarding whether or not to grant a bank loan. Specific, consequential parameters for consideration in that model would be things like collateral, wealth, income, credit score, liabilities. Proxy parameters would be things like neighborhood, race, gender. While something like race will certainly be correlated with insolvency on a loan, it is a secondary characteristic and not actually causally responsible for that outcome. Race, in general, is a key example of a parameter that should be excluded from virtually every such decision engine.<br/><br/>On the flip side of this problem (i.e. including non-causal, secondary parameters in decision engines) would be the problem which has become even more relevant: modifying parameter weights in search of outcomes in order to try address problems with inputs. For example, if the same decision engine described above for giving bank loans were to only consider the relevant causal parameters (income, wealth, credit, etc), it will absolutely be the case that different racial populations would not be represented proportionally with regards to the rate of loan approvals. This sort of thing has led many to refer to the decision engine itself as being racist, despite not having a parameter in any way considering the race of the applicant. This logic, that any disparities in outcomes can be used as evidence of a racially biased decision engine is fundamentally incorrect. The failure to understand that it is the input values to the unbiased decision engine that were already non-comparable between populations is what is resulting in disparate population outcomes is precisely the problem. And should this logic permeate, it would mean that all of our decision engines in society would be actively biased towards producing the sort of arbitrary outcomes sought after by those in charge, rather than attempting to build unbiased engines, and addressing problems with inputs in order to get desired outputs.<br/><br/>In summary, building AI models is extraordinarily useful, but I implore you to avoid building and biasing models in pursuit of particular outcomes. Should the government engage in the usage of AI, there should absolutely be standards regarding the sort of parameters that are admissible into a given function, and as a general rule of thumb: race should never be one of them.",
1,DHS-2021-0015-0090,Comment Submitted by Frank Wellman,I am concerned with the potential abuse that I believe will happen with unregulated use of facial recognition. There needs to be significant safeguards in place before this &ldquo;tool&rdquo; is allowed to be put into wide spread use. ,
1,DHS-2021-0015-0101,Comment Submitted by Benjamin Neumann,"The collection of this information (1) is not necessary to the proper functions of the department and (2) it is not likely that the department will process and use the information in a timely manner. As the the department has not shared the data collection instrument, (3) it is not possible to ascertain whether the estimate of the burden is accurate.<br/><br/>The department believes that the use of artificial intelligence, including and particularly facial recognition, is required and that the public must learn to accept it. The department has already solicited comments regarding final rules involving the use of application facial recognition, such as for Docket USCBP-2020-0062, &quot;Collection of Biometric Data from Aliens Upon Entry to and Departure from the United States&quot;. In the comments for that docket, the department should have learned that it has failed to even provide adequate notice of its use of facial recognition and failed to safeguard the images used (ex.: USCBP-2020-0062-0053). The department continues to insist on the use of facial recognition without acknowledging the dangerous of its use or justifying why it is necessary and justified (ex.: USCBP-2020-0062-0044).<br/><br/>The department already knows about the public perception of facial recognition through its rule making processes. It should stop implementing facial recognition and should not waste time and money surveying the public.",
1,DHS-2021-0015-0033,Comment Submitted by Nathan Blasio,"I am concerned about the widespread adoption and integration of Artificial Intelligence based investigative tools, particularly facial recognition technology. In its current form, facial recognition software presents several problems to American society, including a continuation of anti-Black/Brown law enforcement traditions and threats to everyone&#39;s right of privacy.<br/><br/>Scholars Joy Buolamwini, Deb Raji, and Timnit Gebru have demonstrated the shortcomings of this technology as it applies to race through publications in 2018 and 2019. Their work suggests that AI Facial Recognition technology, despite composed of algorithms, may nevertheless carry racial bias which leads to disparate outcomes in criminal interdiction and enforcement. Even a single mismatch which prompts police action is far too much of a drain on public resources. More importantly, a single mismatch has the potential to ruin one&#39;s life. The false arrest and detention stemming from AI data of a single working mother of color has the potential to drain financial resources, threaten job security, and harm them in a myriad of ways.<br/><br/>Furthermore, the databases for AI recognition are largely composed of arrest and booking photos (&quot;mugshots&quot;). Following the US&#39;s largest civil rights protests in 2020 over anti-Black police behavior, it is hard to ignore the fact that this technology will only serve to perpetuate the racialized history of criminal enforcement even further into the future. As crime data and demographics suggest, despite White and Black folk committing low level crime at equal rates (most prominently: cannabis and traffic enforcement), Black folk are far more likely to be arrested and processed for the same crime. This trend will only be exacerbated by adopting facial recognition technology.<br/><br/>Lastly, facial recognition technology represents another iteration of American domestic surveillance and control. There is already a long history of police surveillance of Black/Brown communities, and this new iteration fails to address any of the problems with concentrating surveillance resources in poorer communities. This technology, with integration of data collected by domestic surveillance on who one talks to, the media they consume, and their associations and political beliefs, forecasts a fearful future where AI based enforcement technology (such as kill drones) can be used to target those based on political ideology. Additionally, although the presumption of the DHS filing this request for comment is to receive public comment regarding the use of this technology as it pertains to &quot;homeland security matters&quot; (notably terrorism), undoubtedly the technology will be applied to ALL enforcement matters. The most invasive forms of authorized surveillance are, surprisingly, NOT used to investigate threats to home security or to stop the actions of violent criminals, but rather crimes relating to drugs/substances. Of course, the history of racialized policing as it pertains to drugs is well known by now, and facial recognition technology is likely to continue the injustices of the war on drugs.<br/><br/>In sun, I encourage the DHS to reject the adoption and integration of this technology as an enforcement tool. Not only does it pose threats to a right of privacy, but its adoption in its current form will only serve to perpetuate disparate enforcement of criminal justice based on race/ethnicity.",
1,DHS-2021-0015-0078,Comment Submitted by Anonymous,"The possibility of misuse for artificial intelligence identifiers is absolutely staggering. Even if the technology worked perfectly (which it doesn&rsquo;t), a clear mandate (which it won&rsquo;t), and with overly sufficient oversight (which DHS does NOT have), this technology is incredibly susceptible to misuse.",
1,DHS-2021-0015-0056,Comment Submitted by Ben Nichols,I am completely against government entities utilizing artificial intelligence and facial recognition to collect information. This violation of privacy does not offer any unique benefits to the general population of the United States. Constant surveillance of the public will only serve to destroy liberties enjoyed by American citizens. This Orwellian proposal by the Department of Homeland Security would threaten to manipulate and control most aspects of every day life of people in America.,
1,DHS-2021-0015-0060,Comment Submitted by Bertrand  Bell,no stop it.,
1,DHS-2021-0015-0064,Comment Submitted by Jerry A,"Facial recognition with AI will be a giant show that will literally cause riots in all big cities if ya&#39;ll ever used it en mass to track the general public. We all know you&#39;re gonna arrest Black, Latino, and Asian people because a lot of them look like they could be twins. But, you&#39;re gonna do what you&#39;re gonna do. I warned ya&#39;ll.",
1,DHS-2021-0015-0066,Comment Submitted by Anonymous,"Our founding fathers would be appalled this is even being considered. The DHS can go to you know where. It shouldn&rsquo;t even exist, the PATRIOT act should be repealed immediately.",
1,DHS-2021-0015-0070,Comment Submitted by Anonymous,"Facial recognition technology is a gateway to distopian breaches in not only personal autonomy, but also personal data and tracking of citizens unacceptable in American society. The ramifications in not only Western states like the UK, where avoiding these cameras are illegal, but also surveillance states like China create even further lack of trust in governments to not abuse this data. The US government has no right in the Consideration or any founding charter to track a citizens movements or digital construction of their face. Not only would such systems cost a great deal in a time already stricken with budgetary overreach, but also rightly would immediately be challenged in all levels of the courts. Data collected would serve little in the way of reducing, or preventing crime, but certainly become corrupted by those with access for their own gain. I oppose such a course by any government or private agency to the upmost of my beliefs. A concerned citizen and servant of the United States of America. ",
1,DHS-2021-0015-0082,Comment Submitted by David Goins,"Though worded a bit confusingly, I do agree that the public should be surveyed on the matters of AI and further facial recognition. Time will need to be spent explaining to us exactly what it is you want to do. Probably news programs and a presidential comment on the importance of public opinion. There is a massive feeling of failure on the part of the government and the constant anxiety of a divided nation, so please be cognizant of that when approaching this. Additionally, there is big distrust with law enforcement and how these devices and programs will be used against people of color and lower income communities, please address that as well. How does the biases of the AI creators not get built in or the biases of law enforcement. Please address the public. ",
1,DHS-2021-0015-0057,Comment Submitted by Anonymous,"Ethical Concerns about emerging technologies, while a grassroots push to outlaw the use of the technologies in various law enforcement applications means there is a need for the Federal Government to study the benefits of AI and Facial Recognition in specific test cases before making any sweeping federal policies. ",
1,DHS-2021-0015-0067,Comment Submitted by M E,"I am highly concerned about government use of artificial intelligence and facial recognition. We have seen over the past few years how much of an invasion of privacy and biased tool AI and facial recognition are when used not only by private companies (Facebook et. al.), but also by law enforcement agencies like local police departments. In addition, we have seen how effective such tools can be to maintain a stranglehold on the constituents of authoritarian regimes. To protect the privacy of Americans we should be exceedingly wary of turning to such technologies.",
1,DHS-2021-0015-0087,Comment Submitted by Anonymous,"My information is already extensively recorded in every financial transaction I make online, in every trip to or from anywhere on a plane, and I interact with the government tracking my every move as a result of this. There is absolutely no place for further dystopia-esque monitoring of Americans on our own soil. Should the government need video of a specific area, they can turn to warrants and requests to local businesses and home-owners. This proposal is an unwarranted, tyrannical overreach of Constitutional allowances afforded to the federal arm.",
1,DHS-2021-0015-0039,Comment Submitted by Anonymous,I do not believe the DHS should be using AI or facial recognition as it is to easily abused to strip Americans of their privacy and rights. There is no reasonable use of this technology by a government agency in my opinion. ,
1,DHS-2021-0015-0035,Comment Submitted by j h,"The use of any facial recognition software by a government entity is easily one of the most dystopian things I can imagine happening. The use of such technology provides too much control over individuals. Even if it were designed with a benevolent end in mind, it would inevitably end up causing unjust bias to creep into the systems that use it, similar to how CCTV cameras have already done (CCTV camera evidence is used frequently in prosecution, this creates an inherent, self-confirming bias against people who exist in areas where such monitoring devices are more prominent. Due to their utility in providing convictions, we will never be rid of them despite the fact that they are inherently a biased tool of justice and simply shouldn&#39;t be used in the first place). Furthermore, there is no guarantee that the government will remain a &quot;benevolent&quot; keeper of this technology indefinitely. By allowing these technologies to proliferate we are literally handing the tools of oppression to whatever totalitarian regime may come into existence next, be it in this country or abroad. The only way to protect individual freedom and privacy is to *not allow this technology to be used by the government full stop*.<br/><br/>P.S. Also, it&#39;s crazy to me that you&#39;re asking for my full name and address to file this as an individual on the internet.  ",
1,DHS-2021-0015-0102,Comment Submitted by Wes Mason,"I think implementing AI and Facial Recognition into American everyday life is a slippery slope that will likely eventually lead to a society more in line with how China likes to handle things. This facial recognition power alone could very well strip Americans of their freedom just a little bit more, and I find that deeply unsettling.",
1,DHS-2021-0015-0103,Comment Submitted by Anonymous,It would be a dystopian nightmare to use AI and facial recognition against your own people. Everyone already distrusts the U.S. government and I bet if you did a better survey than this to ask people they would agree that US agencies like your have taken away their civil liberties. I would also note that this survey is very much flawed as I am written this only six people have written responses it and that is not a very accurate representation of the American population. If your agency would have spread the word of this survey better you would have better results. If you have a database of everyone for your facial recognition and AI it could be stolen by the Chinese and Russians are be used to spy on all Americans.,
1,DHS-2021-0015-0107,Comment Submitted by Anonymous,"The lack of transparency regarding the depth of information collection, as well as how community members affected by analyses and data collection can become part of the process is highly concerning. If these technologies are to be implemented, it is the government&#39;s duty to inform citizens and make sure the decisions made on that data are fair and Constitutional.<br/>Often, bias in algorithms developed on widespread collected data tends to reinforce inequality and worsen security in the long run, as evidenced by numerous applications of predictive policing, hiring policies, and the overall discussion of AI and data collection bias in both public and private sectors. Unless this is made a part of the conversation, it is irresponsible to engage in such data collection in the first place.<br/><br/>Ultimately, solutions should involve:<br/>Community engagement in both civic, non-profit, and outreach measures<br/>Ensuring review as to the security of databases and the use of data; this should be highly regulated and transparent so that operations do not extend beyond their mandate<br/>Technologies used should be apparent and not rely on highly invasive use of privately owned hardware (for example, cell phones or other IoT devices)<br/><br/>The reality is most Americans are unaware of how much they are giving up with regard to data collection, often under the false assumption that they have &quot;nothing to hide.&quot; Data analytics and AI move past this, often in the capacity of how predictive algorithms can affect their lives. This moves beyond knowing what criminal individuals are doing and into how society is shaped in the long-term.",
1,DHS-2021-0015-0154,Comment Submitted by Anonymous,"I strongly oppose the Government rolling out additional surveillance technologies domestically. Americans have strong constitutional protections against such surveillance, including our fourth amendment right protecting us from unwarranted search and seizure. These protections in spirit should prohibit such incursions as the extensive use of AI and Facial Recognition technologies on citizens. In addition, there are other concerns about the inequities of using AIs, and their inherent bias against minority groups. ",
1,DHS-2021-0015-0161,Comment Submitted by J Franklin,"I am strongly against the use of facial recognition. I believe this is a violation of my rights to privacy and against unwarranted search: you must obtain a warrant before tracking me via face recognition. Please do not implement this and further turn the country into a surveillance state. Additionally, there are concerns about how the data will be protected once it is gathered: we all remember the OPM hack a few years ago. Please do not expand the use of facial recognition. Thank you. ",
1,DHS-2021-0015-0119,Comment Submitted by Richard Jolly,"The DHS and the federal US government should not explore Facial Recognition or AI assisted software in the pursuit of criminal investigations. These types of intrusive tools in the pursuit of a &quot;crime free&quot; America, will only lessen freedoms that American citizens enjoy. Indeed, these tools will inevitably be used as a preemptive strike when no crime has been committed. These tools will be used to predict when a crime could occur and even worse predict whom is a criminal. The pursuit of tools to ensure a &quot;crime free&quot; America will not make Americans any safer. Crime will simply adapt to the new tools and find ways to exploit the holes that they new tools have. The DHS and federal government should perform more investigations into what are the top ten fears of Americans. These fears are typically about health and money. ",
1,DHS-2021-0015-0138,Comment Submitted by Anonymous,"Facial recognition should be used only in locations where higher security is absolutely required.  EXAMPLES: When entering/leaving USA is fine. Before boarding a plane or train is fine. When entering/leaving a state or federal government building.  When entering/leaving a military base.  When entering/leaving any highly secure area.<br/><br/>Facial recognition must NOT be used to track everyone on every street or public location.  Society doesn&#39;t want a &quot;big brother&quot; tracking our every move in public locations.  EXAMPLES: walking on a public sidewalk, driving on a public street, walking through a public park, when on a beach, ...<br/><br/>",
1,DHS-2021-0015-0155,Comment Submitted by Anonymous,Facial recognition should be banned everywhere except in prisons. Individuals should have the ability to be discrete and anonymous when in public spaces. Identity checks at other critical places are sufficient and more clearly allow for the individual to give consent to identification or not enter that protected area. ,
1,DHS-2021-0015-0152,Comment Submitted by Anonymous,"Terrible idea, it will be twisted to spy on the people of this country rather than the enemy.",
1,DHS-2021-0015-0156,Comment Submitted by Kimberly Vitiello,"The use of artificial intelligence for facial recognition is very concerning to me as a citizen. It seems to strip away inalienable rights granted by the U.S. Constitution, such as my right to privacy. Constant and increasing surveillance is more the flavor of authoritarian regimes - not the United States. This gives me deep concerns about my civil liberties and seems like this would violate several of my constitutional rights as a citizen, not to mention the concern that AI consistently misidentifies people of color disproportionately. The use of AI in general against citizens seems a herald of dystopic proportions and the evolution of AI is something I am firmly agaainst. This kind of facial recognition technology captures biometric data of every person who is on camera, without their consent, violating the right to privacy and undermining freedom of expression. There are also concerns with growing skill of hackers and the US Government&#39;s consistent data leaks - the loss of vital data on citizens to potential threats is unconscionable combined with the violation of our rights. As a United States citizen, I am deeply and firmly against it.",
1,DHS-2021-0015-0166,Comment Submitted by Anonymous,"As an infosec worker, I have to simply say no. This is a terrible idea and does nothing more than infringe upon the 4th amendment. Not only will this practice yield far too many false positives, it will absolutely be used maliciously. Facial recog. also allows the storage of where this person was, when, and how long they were in this location. <br/><br/>This will also do nothing but make people wear facemasks at all times, which I assume will be made illegal in conjunction with facial regoc. <br/><br/>Lets be real here, this isn&rsquo;t a good idea.",
1,DHS-2021-0015-0147,Comment Submitted by Joel Cornell,Facial recognition is a racist technology built by white supremacists.,
1,DHS-2021-0015-0108,Comment Submitted by Holm Belsheim,"AI has great potential, and great risk. General AI presents too much risk for the US and its current state of inconsistent and frequently out-of-date technological infrastructure, knowhow and skill. Limited AI offers a better ratio of risk-reward, though it needs robust review and oversight to prevent AI from perpetuating system failures and from creating an over-reliance upon technological magic than true changes and improvements.<br/><br/>AI is limitless in promise and advertising. It is also, by definition, ultimately to be without limits. General AI is at its core intended to expand and grow without limit. Narrow AI is designed to have specific parameters. Both present great risk and reward, but General AI, as it is truly envisioned, offers virtually unlimited risk for uncertain rewards. Narrow AI, coupled with robust oversight and review, offers great potential while mitigating much risk from a technological standpoint. It also avoids creating an easy answer for policy makers to pawn off an issue to an easy-sounding technological fix, without clearly understanding the consequences.<br/><br/>The US government has long been fascinated with technology but been poorly equipped to control it. It is a well-known, and often sadly accurate, aphorism that a US government body tends to operate a decade behind the rest of the world. The poorly understood and constantly advancing field of AI is a prime risk for a well-meaning, but unprepared, entity or set of entities to cause great harm with, both now and in the future. Most elected politicians do not have great technological knowhow or understanding, and some even advertise this ignorance as a benefit. While many in the US government do have real understanding, the US government is not set up to broadly share knowledge, oversight and other information necessary for the kind of fundamental changes in capacity that AI offers.<br/><br/>AI embodies a hypothetical silver bullet in some minds: a perfect, evolving response to any issue. What is currently consist of are haphazard and inconsistent systems and processes. Facial recognition is one prime example: while nominally it offers efficiency and results without human failings, its current reality already shows bias, flaw and problems with tangible results.<br/><br/>Facial recognition often demonstrates racial animus. https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/<br/>Facial recognition is often incorrect even within racial groups. https://www.nytimes.com/2020/12/29/technology/facial-recognition-misidentify-jail.html <br/>In some countries, such as the People&#39;s Republic of China, AI-powered facial recognition is a core element of a vast, ever-expanding, repressive and classist social credit system. https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html <br/><br/>Facial recognition has already been abused in private hands repeatedly. Cambridge Analytica&#39;s data-sweeping and the ever-evolving use of deep fakes are 2 easy, recent examples. It can be presumed that such uses and abuses will only continue.  <br/><br/>In addition, facial recognition algorithms and other systems pose dangers to geopolitical alliances. The US has long been closely aligned with Western Europe and allies, such as Australia, through NATO and other entities. Privacy is an increasingly important human right in Europe and has received consistently expanding protection in the past decade. E.g., the GDPR and related enforcement mechanisms have triggered significant changes in privacy and other protocols for many large companies, as well as leading to similar laws in many other major nations. <br/>AI-enabled facial recognition, when applied broadly, does not work with many existing legal regimes and is likely to be even more limited in the coming decades. The US is already struggling to retain and strengthen ties to its traditional European allies, as trade, travel and other connections struggle between increasingly distinct policies on, among things, privacy. Enabling expansive and privacy-intrusive policies, which more often than not depend upon robust AI networks, domestically threatens to distance the US from stable, long-time allies, while aligning us more with nations that more resemble classic antagonists: repressive, autocratic regimes with a poor track record of human rights, non-competitive economies and other values we have often opposed. A default reliance upon AI, including facial recognition, threatens to undercut necessary and substantive alliances, while offering far less tangible and reliable benefits.<br/><br/>AI is undeniably attractive, and will be an enormous factor in human history. The US correctly recognizes its potential significance. However, the existing US track record with AI, particularly with facial recognition, shows numerous flaws and failings. Ongoing and future usage of AI should be handled with a critical eye and robust review.",
1,DHS-2021-0015-0113,Comment Submitted by Anonymous,"Facial recognition and artificial intelligence for use in private, public, and government sectors is a gross misuse of personal identifiers. These systems are not ethical for identification purposes and will not improve the lives or inalienable rights of people. These systems will be used against average citizens and be too costly and not be used to investigate the truly heinous one percent class. This is the beginning of a dystopian police state. Stop gathering data on average people and make it into headlines to hide the acts of the rich and government involved persons.",
1,DHS-2021-0015-0149,Comment Submitted by Mark  M,"&quot;Therefore, understanding how the public perceives these technologies, and then designing and deploying them in a manner responsive to the public&#39;s concerns, is critical in gaining public support for DHS&#39;s use of these technologies.&quot;<br/><br/>No one wants to live in 1984. We like our privacy. We don&#39;t sacrifice our freedoms to satiate the latest government control pangs.<br/><br/>If that&#39;s not possible, then make daily facial recognition check-ins and assignment or provide people with a drone that follows them around and records every move. ",
1,DHS-2021-0015-0158,Comment Submitted by Eric Brewer,"While I understand that there are legitimate national security and law enforcement needs for this kind of technology, I am afraid the potential for harm outweighs the potential for good in this particular instance.  If we could rely on no misuse of power, then this technology would greatly aid in assisting in keeping the public safe, but if history has taught us nothing, is that this can, and will, be abused.  As such, the only reasonable alternative is to prevent the use of the technology in the first place.  That is also coupled with this technology isn&#39;t reliable enough yet to allow its influence on crucial decisions like guilt or innocence of a crime. I work in the IT field, and there is a concept of acceptable reliability, which is the 9 nines.  that something needs to be reliable 99.9999999% of the time to be considered a viable option.  Right now, facial recognition technology has a proven track record of performing worse on people with darker skin complexions, and until this technology reaches a level of proficiency that would be acceptable for corporate culture, then it should not be allowed to integrate into a process that determines if someone gets to keep their freedom.",
1,DHS-2021-0015-0116,Comment Submitted by Anonymous,I feel facial recognition is breech of personal freedom. It&rsquo;s a system that is easy to abuse when the public isn&rsquo;t allowed behind the curtain. We cannot move towards becoming more of a police state if we are to maintain our freedoms. ,
1,DHS-2021-0015-0123,Comment Submitted by Matt Ralston,"I believe that AI assisted technologies are important for the recognition of criminals in controlled settings like airports and certain other transportation related activities, as well as for the protection of certain personnel. However, there is no governing body or regulatory agency that oversees the use of this data or integrations (pulling or releasing data) with other law enforcement systems. There is no guarantee that the public can trust the government with what is dangerously close to violations of amendments. Can you devise a system of control that tightly restricts such usage, restricts executive or justice overreach, and/or is subject to occasional external review by the public without possibility of draconian interference from a stubborn and even paranoid congress?<br/><br/>I don&#39;t think you can.<br/><br/>In that light, I suggest that instead of insisting the technology and regulatory system is ready for prime time, or insisting that the free market decide, that you instead suggest that existing uses be subject to thorough review and efficacy studies until society has time to adapt and evolve and understand these technologies and their actual benefits and actual worst case scenarios.",
1,DHS-2021-0015-0127,Comment Submitted by Anonymous,I don&rsquo;t understand how this isn&rsquo;t a direct infringement on our Fourth Amendment rights.  The ability of the government to recognize any face in a crowd and then trace that person using AI effectively means anyone within the dataset that the government has access to is being searched.  The Department of Homeland Security is already doing a poor job of securing our airports with the existing invasive technology already at their disposal (see https://www.mercurynews.com/2019/12/20/whistleblower-says-tsa-is-trading-speed-for-security/amp/) and should not be allowed to further violate our rights.,
1,DHS-2021-0015-0134,Comment Submitted by Anonymous,AI driven surveillance. <br/><br/>Just another tool in the totalitarian belt.,
1,DHS-2021-0015-0148,Comment Submitted by Mitchell Simmons,Privacy is protected in our constitution. Respect the fourth amendment.,
1,DHS-2021-0015-0165,Comment Submitted by Anonymous,I stand against AI facial recognition. I do not see our founding fathers giving way to this and therefore neither should the standing government. This is easily an infringement on constitutional rights and therefore can&#39;t even reason why this is being debated. ,
1,DHS-2021-0015-0160,Comment Submitted by Anonymous,"I disagree with the use of facial recognition technology and other AI implementations used to track, monitor, log, identify, or otherwise.",
1,DHS-2021-0015-0121,Comment Submitted by Anonymous,Facial recognition technology should be left out of law enforcement. It will only be used to intensify state and corporate surveillance and control,
1,DHS-2021-0015-0136,Comment Submitted by Anonymous,"I am absolutely against the DHS having access to and relying on facial recognition AI. The software is horribly inaccurate, and doubly so with PoCs. It is also expensive, and thus triply so for a government organization. ",
1,DHS-2021-0015-0144,Comment Submitted by Drew Gehringer,Facial recognition technologies can very easily be used to violate constitutional rights or be abused for personal reasons by people with access (see: the NSA and &quot;loveint&quot;). Will Homeland security actually consider those legal ramifications before deciding whether or not to plow on forward?,
1,DHS-2021-0015-0177,Comment Submitted by Anonymous,"Joe I understand that you have memory issues, but that is no excuse for the breach of privacy that is mandatory facial recognition placed upon public utilities. As a citizen I could not resent this to any greater degree.",
1,DHS-2021-0015-0175,Comment Submitted by Anonymous,"Facial recognition doesn&#39;t really work. The results will be horribly wrong for demographics, ethnicities, races not covered in the training set.<br/><br/>Capturing and storing a face model is a much bigger invasion of privacy compared to fingerprints. The potential for abuse is too much and the data should not be collected.",
1,DHS-2021-0015-0178,Comment Submitted by Kaleb Zimmerman,"While incorporating new technology into these systems is bound to happen eventually, at this point, it&#39;ll do a lot more harm than good to invest so much in surveillance. <br/><br/>I can&#39;t really see any effective and constructive use for this.<br/>-Find terrorists before they strike/criminals after they crime? The accuracy/efficacy of facial recognition and AI management is depressingly lacking. Any company with an &quot;automated help desk&quot; should infer this for you. <br/>-Keep us safe and secure? From what, ourselves? That&#39;s just going to make people paranoid, especially since our leadership changes every few years, sometimes with vastly different views on &quot;Rule of Law&quot;, or definitions of &quot;citizen&quot;.<br/>-From foreign powers? It&#39;d be a point of weakness, mainly by just opening another route to get at citizen&#39;s juicy private data. I don&#39;t want some crazy person to get me arrested for something stupid because they found a still of my face withdrawing cash and decided to cause a little discord to their geopolitical rival with some false accusations.<br/>-Keep track of us for census data? While that&#39;d probably be the most benign use for AI (though not facial recognition), The idea of &quot;The government is tracking you.&quot; is just going to cause more public backlash and distrust than it&#39;s probably worth. <br/><br/>If you absolutely must do this then I can&#39;t stop you, but for god sake&#39;s keep human oversight over the thing and don&#39;t just blindly trust it. I don&#39;t want to read about minorities being more afraid of the government than usual, or the next vague-faced person being haplessly accused of something they didn&#39;t do.",
1,DHS-2021-0015-0181,Comment Submitted by Kody Zalewski,"Trust in the American government continues to plummet, rolling our facial recognition AI technology would only serve to degrade the already precarious position of faith in American institutions. There is also reason to believe there would be little impact on ameliorating crime using these tools. Researchers have already collected ample evidence that facial recognition is extremely fallible, and often mislabels faces of PoC. We can&#39;t risk further exacerbating the problem of over-incarceration in vulnerable communities. This would merely be another costly extension of the &quot;security theater&quot; that is superficially (and ineffectually) geared toward public safety while destroying trust in American institutions. ",
1,DHS-2021-0015-0015,Comment Submitted by Anonymous,Facial recognition is a huge danger to privacy and civil rights.  ,
1,DHS-2021-0015-0024,Comment Submitted by Mikala Rhodes,Never in a million years ,
1,DHS-2021-0015-0019,Comment Submitted by Anonymous,"As an American, I believe the best way to sell and implement these technologies is not at all at this time. Until we the people are given our deserved rights to our data, and subsequently property ownership of our data, can we move forward with addressing the numerous problems with this technology and its racial biases, and its intent in a functioning society. Those at the DHS, and those developing AI technologies, looking forward to making big bucks on a sale should take a long time to think about what laws could change in the future that could criminalize them. They have their thumb on the scale of the surveillance state, and without putting in protective measures of the rights of citizens of any developed country in the world, let alone the U.S., you&#39;re asking for a new age of unjust criminal crackdowns, ANOTHER mass incarceration, and extrajudicial executions. Please refer to the Wikipedia link for Civilian casualties from U.S. drone strikes (https://en.m.wikipedia.org/wiki/Civilian_casualties_from_U.S._drone_strikes#:~:text=The%20New%20America%20figures%20report%20that%3A%201%20The,there%20were%20a%20total%20of%20263%20U.S.%20) a future practice aided by AI technologies.",
1,DHS-2021-0015-0190,Comment Submitted by Anonymous,Facial recognition should not be used under any circumstances. It is a massive violation of privacy and is not worth it.,
1,DHS-2021-0015-0191,Comment Submitted by Anonymous,"I shall answer the questions you posed below with additional comment after:<br/> <br/>(1) Collecting data on persons is essential to the function of DHS. However, the real question should be not &#39;is the collection of this data essential&#39; but &#39;is it ethical/ an overreach&#39;? Without a strict definition of how and where this data collection is taking place, we the people cannot respond to the two important questions with accuracy. Any collection of data not taking place in a clearly marked area under direct control of DHS or Border Patrol is a clear ethical violation. In collecting the data covertly (i.e: somewhere not clearly labeled as being used for this program) subverts an American&#39;s right to privacy. Even in public locations, there is a basic expectation to privacy insomuch as you are not expecting the local shop&#39;s CCTV to be giving their data to the gov&#39;t unless there is a warrant on the data due to a crime taking place. This is not London or China. We enjoy, expect, and value our right to act as a private citizen without an undue burden of surveillance.<br/><br/>(2) No, it will not in the slightest. The data processing will take time. Then, a human will have to sort out false positives, all before the data has a chance of being actionable. That is assuming that you bother to evaluate false positives. Depending on how much data you are processing, a day&#39;s worth of data could take a month to process before it even gets to a human.<br/><br/> (3) No, see above.<br/><br/> (4) Don&#39;t use AI in the first place. It is racially biased and still in its infancy. <br/><br/>(5) You can&#39;t. There are some jobs that should not yet be shifted over to technology. Saying &quot;this person is the criminal&quot; should be considered as one of the most delicate and awesome (in the old fashioned meaning of the word) task a person can undertake. Therefore the agency should not be able to say &quot;oh, our technology made a boo boo&quot; and write it off. If you are pointing a finger at someone, they should be able to point a finger right back at you and say &quot;this particular agent fucked up&quot;. To put any human through whatever legal process they would be subjected to with this potential technology should be considered with the utmost caution and I cannot see DHS taking that seriously. <br/><br/>Until such time as the technology can reliably make facial recognition matches that are not racially biased AND IS ONLY used in clearly designated places, I do not see any way that this is an ethical, moral, or legal use of the budget.",
1,DHS-2021-0015-0193,Duplicate Comment Submitted by Eric Yale,"Facial recognition of the general public is one step closer to a Totalitarian Government as it serves only to categorize American Citizen&#39;s into groups that provide Government Officials the ability to identify those citizen&#39;s who agree or disagree with their form of Governmental control.<br/><br/>Like ALL forms of Government oversight, this to will be abused irrespective of the guidelines or Laws for its use.  There is currently NO oversight feature used by the Government that has not been abused and will continue to be abused by those who seek total power and control over the citizenry.  <br/><br/>Given those who today and over the past decades have NOT been held accountable for unlawful acts against American citizens, I am OPPOSED to allowing the use of Facial recongnition programs for the general public. ",
1,DHS-2021-0015-0198,Comment Submitted by Georgi Stefanov,Facial recognition should be banned! I do not agree with this in any way!,
1,DHS-2021-0015-0196,Comment Submitted by Julia Pirani,"Even if facial recognition software reliably avoided replicating human cosmetic and racial biases, which it categorically fails to do, it would be impossible to ethically or lawfully implement. Proper functioning of the IDENT system requires DHS to profile hundreds of millions of civilians, including American citizens, linking their faces and names to their known aliases and travel history. Domestic systems such as Clearview AI are even more intrusive, allowing DHS to track individuals&#39; activities nearly anywhere within the United States, and link this data with their online activities.<br/><br/>There has been little certainty in American law as to what constitutes a &quot;reasonable expectation of privacy&quot; as protected by the fourth amendment. What is certain, however, is that continued use and expansion of facial recognition software by DHS would permit no expectation of privacy in any area accessible to the public without extraordinary efforts on the part of citizens. Some specialized tools, such as censor masks, may restore this expectation, but only in a limited capacity and at increased cost. Every citizen who did not pay this cost would be completely stripped of any right to privacy by constant warrantless surveillance. This data collection on its own would constitute a violation of the fourth amendment, even if no DHS agent were ever to view or use the data.<br/><br/>The continuance or expansion of such facial recognition programs by DHS is impossible to conduct except by illegal means. The only option is to discontinue the program at once; any other decision would be a flagrant violation of Americans&#39; constitutional rights.",
1,DHS-2021-0015-0200,Comment Submitted by Anonymous,"I lived in China. Facial recognition will turn a free society into a digitized prison, like a modern pig pen, where someone/some machine is constantly checking the temperature, location, status of the pigs.<br/><br/>This will stifle the USA in the long term. If you care an ounce for your children and future generations, you should stop it for the greater good.<br/><br/>Freedom gave birth to the greatest country and it will keep it great.",
1,DHS-2021-0015-0189,Comment Submitted by Anonymous,"We Americans are free people and wish to remain free. Free from government surveillance, monitoring, tracking. The spirit of the Constitution and Declaration of Independence and Bill of Rights is to preserve our liberty by protecting our rights to individual sovereignty and self-ownership. When organizations begin tracking us we are no longer free. When organizations can identify us without or consent we are no longer free. This is a step closer to slavery than it is to freedom. In America, we don&#39;t want safety or protection. In America we value freedom above all else and are willing to live in a more dangerous world if it means being more free.<br/><br/>AI is fantastic technology and I&#39;m sure in the right hands it will one day make the world a better place. But the DHS is not the right hands. The DHS is supposed to protect us from enemy threats, why then would they want to use AI facial recognition technology on us? We are supposed to be the ones being protected, not the ones being watched. America was once a shining beacon of hope in the world. But our government and its institutions have lost their moral compass. Lost focus of what their purpose is. It&#39;s to protect freedom, not people. To preserve freedom, not safety. To make the people in this territory more free, not more comfortable. Freedom is everything, it is 100%, and nothing matters more for us. As we travel through time from our dark past of violence, slavery, and suffering into our uncertain future it becomes increasingly critical that we reevaluate the necessity, the usefulness, the methodology, and the morality of our nation&#39;s institutions. <br/><br/>At its core nature, tracking and identifying people is immoral, unethical, and violates a persons freedoms. If the DHS implements this technology, let it be known that they will be engaging in criminal acts that violate the sanctity of the human spirit. We the people would prefer to face the dangers of being free from this technology than to be under surveillance. In any way, shape, or form. We the people would prefer to hold onto our right to move freely without anyone knowing about it.<br/><br/>",
1,DHS-2021-0015-0204,Comment Submitted by Anonymous,"No. Even with the best of intentions this program will inevitably violate American&#39;s rights to privacy. This information will likely be hacked or fall into the hands of ne&#39;r do wells, compromising security of American citizens.",
1,DHS-2021-0015-0210,Comment Submitted by J R,"The use of AI in general and in facial recognition by government (and private) entities is worrisome on several levels.  First, AI is known to have inherent biases, and it operates without the cultural contexts and moral compasses that humans do. Moreover, with true AI, it is nearly impossible to find out why AI systems make the decisions they do (the &quot;black box&quot; problem), so it is difficult to identify or correct problems in AI&#39;s decision-making.  Human review of AI decisions that impact individuals, particularly ones that impact people&#39;s freedoms, is essential, but I fear that once AI systems are implemented, the entities using them will be too lazy or lack the funding to properly oversee them.  <br/><br/>Second, AI systems intake and produce huge amounts of data.  AI systems need lots of information to train, which in turn requires monitoring and recording of their human subjects, including video surveillance, online activity, use of credit cards, and more.  Implementation of AI thus could be use to justify additional erosion of US citizens&#39; privacy to gather the information the AI systems need.<br/><br/>Finally, these systems can be hacked and the information used for nefarious purposes, both by domestic and foreign parties.  Examples of police and government employees&#39; abuse of information to which they have access are not uncommon.  <br/><br/>There&#39;s a reason China conducts such extensive surveillance of its citizens - authoritarian control.  Is that what the US government wants - complete control over what its citizens say and do?  Because using AI to watch what we&#39;re doing and decide whether it&#39;s acceptable is a big step in that direction.<br/><br/>Whatever we gain by using AI will not compensate for what we will lose.",
1,DHS-2021-0015-0212,Comment Submitted by Melanie Ehrlich,"This is an ineffective and inefficient approach, an overwhelming overreach, and massive invasion of privacy. It is terrifying to know that this is being discussed in a setting largely inaccessible to the average American--if I hadn&#39;t stumbled across a post in a private forum mentioning this discussion within the one (1) single month it is open, I would never have even known it was even happening. Use of any surveillance method or any potential infringement on our rights, privacy, personal data, and civil liberties like this should be OPT IN ONLY, not opt OUT, without the deceptive practices common among web sites and services that engage in the sale of personal data. The potential for abuse here FAR outweighs the potential &quot;benefit&quot;.<br/><br/>It&#39;s clear from the other comments here that the public is overwhelmingly NOT in favor of government/public use of AI and facial recognition technologies, to the extent that this could only proceed if public comment is completely ignored here; the people have spoke and it&#39;s clear they--we--DO NOT WANT THIS.",
1,DHS-2021-0015-0008,Comment Submitted by Stacie Jones,"I am concerned about the use of artificial intellegence in the provision of law enforcement/homeland security activities. Recent research has indicated that the use of artificial intellegience negatively impacts people with dark complexions. I would like to understand how DHS intends to address and solve for those issues, so as to avoid contributing to systemic inequities. Please see:<br/><br/>https://time.com/5520558/artificial-intelligence-racial-gender-bias/",
1,DHS-2021-0015-0020,Comment Submitted by Adam Henaghan,"not only stop, but criminalize biometrics. this is disgusting. ",
1,DHS-2021-0015-0022,Comment Submitted by Anonymous,"Facial recognition software is not at a stage where it should be commonly used for government practice.  This is merely one example of why the technology simply isn&#39;t at a level of competence that it can be trusted.<br/><br/>https://www.cnn.com/2021/04/29/tech/nijeer-parks-facial-recognition-police-arrest/index.html<br/><br/>There have been a number of hearing in Washington State that cover the shortcomings of facial recognition software at every level of the process as well.<br/><br/>From a practical standpoint, it&#39;s an unreliable tool at best and a diplomatic incident waiting to happen at worst.  Choosing to rely on the unreliable is not an acceptable decision for a government agency.",
1,DHS-2021-0015-0016,Comment Submitted by Anonymous,How do you plan on fixing the privacy problems with facial recognition?,
1,DHS-2021-0015-0025,Comment Submitted by Anonymous,"Our government, has shown itself to be fallible in many regards when it comes to violating the privacy rights of Americans (Example: Four major FISA Court opinions on Section 702 in 10 years documenting substantial non-compliance by the FBI with the rules meant to protect Americans&rsquo; privacy). Batch queries, facial recognition and AI assisted algorithms touch the personal data of American citizens who have done nothing wrong which equates to improper search and seizure violation of our 4th amendment rights.  <br/>Our government (local, state, federal) can&#39;t be trusted to hold and protect the personal data which could be used in surveillance from leakage which puts Americans at risk (Example:.2020 cyber attack against US federal government agencies or the 2020 election). <br/>Unlike HIPAA, The limits and scope of this type of data collection are unclear. It is unclear who owns accountability for use of data.  It is unclear who owns accountability and reparations for breach or misuse of data including self-reporting of breaches.  Oversight and regulation are the purview of non-elected individuals who can be influenced.<br/>To those in DHS, thank you for your service. ",
1,DHS-2021-0015-0023,Comment Submitted by James Buto,Facial recognition software should be illegal. There is too much potential for abuse.,
1,DHS-2021-0015-0018,Comment Submitted by Casey Williams,"I am concerned about the use of artificial intellegence in the provision of law enforcement/homeland security activities. Recent research has indicated that the use of artificial intellegience negatively impacts people with dark complexions. I would like to understand how DHS intends to address and solve for those issues, so as to avoid contributing to systemic inequities.  Furthermore, tangentially Facebook claiming deletion of face data, I would like to see more proof in the underlying training data from those images be deleted too incorporated into all AI legislation.  I feel we are being told half-truths to save face. Please see:<br/><br/>https://time.com/5520558/artificial-intelligence-racial-gender-bias/",
1,DHS-2021-0015-0026,Comment Submitted by Anonymous,I am concerned that the DHS will use AI and facial recognition tools to further erode the rights of Americans as set in the Constitution.   It seems that all protections go to law enforcement (who are above the law and in the vast majority of cases without consequences for suppression of human rights to Americans) while these tools are used against ordinary Americans.   So this will be one more broad tool used to suppress our rights.<br/><br/>At a minimum the DHS should be working to support Americans trying to make all our lives better.  One way would be to provide meaningful national statistics on all the varieties of police violence.  ,
1,DHS-2021-0015-0017,Comment Submitted by Anonymous,using facial recognition software on US Citizens is a violation of the 4th Amendment! US Citizens should not be treated like criminals!,
1,DHS-2021-0015-0014,Comment Submitted by Anonymous,I do not support the use of AI and facial recognition in any capacity because it will inevitably be abused regardless of any checks or balances put in place.,
1,DHS-2021-0015-0061,Comment Submitted by Police State,"You aren&#39;t asking for permission to use these technologies, you&#39;re asking how do you make people feel better about it, or more likely, how do you make people unaware that you&#39;re using it.<br/><br/>&quot;DHS has already used or piloted AI-based technologies in several of its key functions, including customs and border protection, transportation security, and investigations.&quot;<br/><br/>So there&#39;s a few ways to go about this. You could notify the public by putting it in fine print on the DHS website somewhere no one will ever look. That way you can say the information is easily accessible to the public. If you&#39;re accused of hiding this information you can show it has been publicly accessible the whole time. That&#39;s a common strategy typically used when it would be worse to be caught actually hiding information.<br/><br/>You could overtly display the use of these technologies. I would prefer to be made aware of when and where these technologies are being used. If it is being used in a location such as an airport or border patrol check point for example, then a fixed placard (see attached) should be in place and visible before entering the area where these technologies are being used.<br/><br/>The added benefit being it could lead to a false sense of security for locations that don&#39;t have signs posted, but the technology is still in use.<br/>And you could give the illusion of choice. For instance if you&#39;re at a border patrol check point you could be given the choice to not be subjected to facial recognition, but then you have to wait longer or hassled for more proof of identification and such, so it feels like you might as well just submit. And if you repeatedly ask what they are trying to hide you can make them feel guilty even if they have done nothing wrong.<br/><br/>You could also check with the Chinese government to see what they do to notify their citizens when facial recognition software is being used. I&#39;m sure the Uighur people would love to share their opinions with you.<br/><br/>Hope this was helpful!<br/><br/>The right of the people to be secure in their persons, houses, papers, and effects, against unreasonable searches and seizures, shall not be violated, and no Warrants shall issue, but upon probable cause, supported by Oath or affirmation, and particularly describing the place to be searched, and the persons or things to be seized.",
1,DHS-2021-0015-0041,Comment Submitted by Briggs Dorian-Lawrence,"Please do not rob me of my right to privacy by using facial recognition and other AI-powered data mining and analysis tools. This is already done by numerous corporations and the world is a worse place for it. Please don&#39;t turn America into China, or into a Cyberpunk dystopia.",
1,DHS-2021-0015-0074,Comment Submitted by Anonymous,I am very much against the use of ai and facial recognition technology. This sounds like creepy police state stuff. Figure out a way to make all future comment periods more well known it&rsquo;s horrifying that only 4 people before me have commented it feels like homeland security is trying to keep it secret enough so only a few complain but technically have an open comment period to cover their when congress starts asking questions in a few years.,
1,DHS-2021-0015-0059,Comment Submitted by Anonymous,"I am against governmental surveillance of citizens without warrant or due process.  This technology is rife for abuse, and is already being abused.  It is disheartening that the question is asking how to make it more popular, rather than whether the populace will allow it.    ",
1,DHS-2021-0015-0069,Comment Submitted by Aaron Boshers,"FULL STOP<br/>DO NOT PROCEED.<br/>AI and facial recognition needs strong privacy laws first, with proper safeguards before ANY implementation. <br/><br/>1984 was not a how to manual. <br/><br/>US cyber needs more funding than homeland security, we&rsquo;re so far behind. we need to be securing our networks and users online than spying on them. <br/><br/>With the overwhelming amount of self shared data this is not needed go get your OSINT like everyone else.<br/><br/>",
1,DHS-2021-0015-0081,Comment Submitted by Anonymous,Using facial recognition technology is a violation of the 4th Amendment to the Constitution.  Facial recognition technology and AI are proven to be inaccurate and biased.  ,
1,DHS-2021-0015-0094,Unrelated Comment Submitted by Anonymous,Homeland Security,
1,DHS-2021-0015-0045,Comment Submitted by J T,"The United States government has proven itself to be a poor broker of data information, and an even poorer judge of characters and values. Under no circumstances should the US government be allowed to continue its intrusion on the privacy rights of its citizens. The government&#39;s inability to protect the most vulnerable and to treat the information and data with the respect it should be given has been displayed since 9/11/2001.  The government has no additional need for surveillance or weaponry.",
1,DHS-2021-0015-0050,Comment Submitted by Anonymous,"Privacy is a US right, enshrined by the justice system. Famously, in Griswold v. Connecticut (1965), the supreme court ruled &quot;the First Amendment has a penumbra where privacy is protected from governmental intrusion&quot;. This application in the modern age, that of information (e.g. personal like facial recognition information) should NOT be used, as an intrusion of privacy. In general, facial recognition would be an intrusion of constitutionally defined rights for it&#39;s personal relationship to a person and necessary information to acquire accurate facial recognition for a person.<br/><br/>Additionally, AI would pose issues regardless of the information use. Unless properly inspected, maintained, and publically available, there will be no proof that the service would be respecting the rights of all and properly following protocols in fairness (even with correct data) unless the algorithm is transparent. The new neural networks, mentioned for their prominence in modern AI, prevents the dignity of humans from being preserved by the lack of transparency, therefore further obscuring what is justice and what is not. Even with desirable system characteristics, the data must be carefully obtained and processed. All would need to be public and explainable in order to be fair. Likewise, one must be informed. It is unfair for someone to assume they aren&#39;t using an AI for a task, and likewise people should always have the choice of using non-AI means should their beliefs and circumstances necessitate it.",
1,DHS-2021-0015-0086,Comment Submitted by J C,This is an insanely invasive procedure than can only be used horribly and invade the privacy of Americans. This is the first step toward a system similar to the Chinese and every man and woman should be against it.,
1,DHS-2021-0015-0032,Comment Submitted by Anonymous,"You answer to the people, and the people do NOT want any level of state surveillance, and especially not any form of facial recognition or biometric tracking. The polls show this time and time again. To try and find a way to &quot;sell&quot; it to us is disgusting, and you should be ashamed of yourselves for having any role in such implementation. YOU, the reader, have an obligation to the United States and the human rights of its citizens to oppose ANY form of warrantless spying. To do otherwise is treasonous and grossly immoral.<br/><br/>There is an increasingly clear division between the interests of powerful individuals in our society and the common man. Please, do not tip the scales any more in the favor of the ruling elite. For once, do the right thing. If the human right to privacy is eliminated, we will never get it back because it will NEVER be in the power-hungry&#39;s interests to do so.<br/><br/>It has to stop. The PATRIOT Act, Stingrays, biometric data collection...all of it. And it has to stop now.",
1,DHS-2021-0015-0048,Comment Submitted by Anonymous,No. Stop. This is one of the worst ideas I&#39;ve ever heard.,
1,DHS-2021-0015-0052,Comment Submitted by T. H.,"There are times when providing identification are appropriate and necessary for individuals in our country, however the expectation that we tape that ID card to our forehead at all times while in public would be a gross over-reach for any organization or institution. Name tags may publicly identify an individual, but with limited information for a defined purpose and they can be removed at will. I do not support the use of facial recognition technology for use by the department of Homeland security or any department of the USA.",
1,DHS-2021-0015-0072,Comment Submitted by Robert Beverly,"No, this idea is terrible and of great concern. It will trigger civil liberties lawsuits, and it will cause extra work for the government at no benefit. Even now, the problem isn&#39;t that we know what all the potential terrorists look like, it&#39;s that we don&#39;t know what they look like and probably don&#39;t know who they are. Facial recognition software does nothing for this problem. But it threatens the privacy of citizens, and arguably restricts their civil liberties.<br/><br/>In the event of a breach of DHS systems, which is almost guaranteed to happen eventually, such a massive facial recognition database also puts many people who are not even targeted at risk. Undercover LEOs, diplomats and intelligence workers can be outed or spied on by anyone with access, or any beneficiary of a data breach. This can lead to kidnap and ransom, loss of LEO personnel, and even introduce new threats to national security.<br/><br/>The false positive rate is typically not thought through properly in such systems, and people are intuitively aware of this. We&#39;ve all heard about cases where a terrorist threat was identified overseas, but the data was wrong... resulting in deadly attacks on the wrong target, even allies. Are we willing to move in that direction on our own shores? I certainly hope not. I for one do not want to be apprehended by a SWAT team because my facial features and nervous pacing patterns are an 83.33% match with someone else who is thought to be 94.72% likely to harbor terrorist intentions. In reality, it&#39;s like any tyest that fails to consider that the base rate of actual terrorists is less than 0.1% of the population; a positive match will actually mean that there&#39;s an 90% or greater chance the person is NOT a terrorist, and was simply mis-classified. Yet the result will invariably be interpreted as a &quot;threat&quot; to personnel. As a citizen I prefer to worry about fewer things, and the idea that my every move is going into a database that could someday misidentify me as threatening is not one of the things I would like added to my worries.<br/><br/>So no, I am not in favor, and I think there are many people who are concerned with privacy, civil rights, discrimination-as-algorithm, and departmental overreach, who would strongly agree that this is a bad direction for DHS. If you know of a terrorist, by all means apprehend them before something bad happens. If not, it doesn&#39;t accomplish anything to start cataloging all the faces and running them through AI... rather, it is counter-productive and damaging to public morale.",
1,DHS-2021-0015-0095,Comment Submitted by Travia Hinton,"Facial recognition is solely acceptable if facial models are in no way attached to persons, whether individually, through demographics, or otherwise. The danger of foreign intervention is too high to maintain an identified database of facial features.",
1,DHS-2021-0015-0084,Comment Submitted by Anonymous,Ai and facial recognition technology used by the government has minimal impact to actual law inforcment and will be used to erode the rights of the average citizen. This overall does not benefit any citizen other than agency who will not let us audit this data. This data would be automatically collected and used by Lord know who. While the intent may seem like a good idea it will eventually be abused.,
1,DHS-2021-0015-0043,Comment Submitted by Daniel Bright,"Facial recognition and AI tech are immature and ripe for abuse by bad actors and unethical organizations. More development of the underlying tech, along with more robust frameworks of rules and regulations must be established well in advance of implementing any tech for use on or against the American public.  This question should be better publicized, and I think if it was we could assume what the response would be.  It is unethical and short sighted to present this question in this manner - you are constraining the publics understanding of the issue and their associated ability to comment on this topic.<br/><br/>A clearer understanding of the concerns and challenges should be established to avoid bias and other concerns.",
1,DHS-2021-0015-0047,Comment Submitted by Anonymous,"I am concerned about the use of artificial intellegence in the provision of law enforcement/homeland security activities. Recent research has indicated that the use of artificial intellegience negatively impacts people with dark complexions. I would like to understand how DHS intends to address and solve for those issues, so as to avoid contributing to systemic inequities.<br/><br/>I&rsquo;m also generally concerned with American&rsquo;s rights being trampled for &lsquo;security&rsquo; - will this require a warrant for use or is this the new we don&rsquo;t need a warrant to track people?",
1,DHS-2021-0015-0065,Comment Submitted by Jimmy Remy,AI bias must be thoroughly checked before being used on the public. Please bear in mind that a program like that is only as good as it&rsquo;s developer(s),
1,DHS-2021-0015-0075,Comment Submitted by Robert Brown,"I am strongly against the use of artificial intelligence by the DHS, especially facial recognition software. There are serious concerns concerning the security and privacy implications use of these tools brings. ",
1,DHS-2021-0015-0083,Comment Submitted by Anonymous,"In concept, I don&#39;t have an issue with the use of facial recognition technology to promote a safer society. The line is crossed when that data is gathered needlessly. In order to protect citizens&#39; personal data from being abused, a warrant should be required to access any facial recognition data. There is simply too much to be gained from this information ending up in the wrong hands; additionally, corporations shouldn&#39;t be able to profit off the use of my face in any capacity. We should use this technology to promote a more secure country, but set the bar high for accessing the data it generates. Of chief importance, facial recognition data should be protected under the fourth amendment.    ",
1,DHS-2021-0015-0091,Comment Submitted by Aaron Sargent,I have a 100% negative opinion on facial recognition technology. No matter what any authority says these technologies are always abused to the detriment of citizens who simply are living their lives because the powers that be on every side are deathly afraid of even the smallest &quot;threat&quot; to their power. <br/><br/>I will never accept facial tech as a security replacement for simple actions like logging into my personal accounts or entering businesses. I know what you&#39;re types are doing thanks to america&#39;s second &quot;9/11&quot; a.k.a the covid-19 pandemic.,
1,DHS-2021-0015-0097,Comment Submitted by Anonymous,The use of facial recognition and AI violate several of our constitutionally protected rights. I DO NOT support the use of these technologies. ,
1,DHS-2021-0015-0106,Comment Submitted by N Finnegan,"AI should not be used in facial recognition or in security or privacy issues. One issue is that the biases of the creators (mostly white men in silicon valley) are inherent in the AI themselves, leading to a heavily biased system that reinforces the inequities in our society. Just look at the facial recognition with Asian faces to see the biased outcomes! AI also uses a tremendous amount of energy; with global warming impacting us now, the idea to spend federal dollars on technology that will not only speed up our carbon output but also push us further into an authoritarian society is not in the public&#39;s interest. Furthermore, the Supreme Court has ruled on our right to privacy. Case law needs to be updated on facial recognition and the use of AI in security before the federal government puts money into a system that is categorically wrong.<br/><br/>I am for the idea of AI in closed systems that do not interfere with people&#39;s privacy and security. However, the technology for renewables is not far along enough to make AI an ethical choice. Facial recognition violates the principle and right of anonymity in the public sphere. I, and many like me, am disappointed in the government seeking to create a state like the CCP. We strive to be a free country, but this government seeks to control through a police state. Put the money (and carbon emissions) to better use please. Perhaps a federal police academy that can train ethical and intelligent police officers? Or towards mitigating global warming impacts like ocean rise on the eastern shore of Maryland or wildfires in Paradise?<br/><br/>Thank you.<br/><br/>",
1,DHS-2021-0015-0170,Comment Submitted by Some Guy,"Facial Recognition through AI risks our Constitutional rights protected by the 4th amendment and puts us a step closer to the same authoritarian system as China. Our allies don&#39;t condone facial recognition AI, but our adversaries do.  We should have the freedom to go about our lives without the fear of Big Brother watching. Our democracy and personal freedoms are withering each day, the last thing we need are technologies that can and will be abused by those in power.",
1,DHS-2021-0015-0129,Comment Submitted by Adam Smith,"Governmental facial recognition, data collection, and similar technologies should not be allowed(or for private/ business) . This and other invasive technologies are often unconstitutional, an invasion of privacy, and easily abused. They should be highly restricted and generally illegal. ",
1,DHS-2021-0015-0157,Comment Submitted by Alexander Huttleston,"I find the proliferation of facial recognition, artificial intelligence, and surveillance, especially of the American people, extremely disturbing. I am an avid user of technology and embrace the many advantages in the workplace and my own personal life. However, I fear what expanded surveillance will do for society.<br/><br/>The advantages of facial recognition, artificial intelligence, and data mining to law enforcement and the government are great. However, the risks to our fabric as a free society are far greater. The harms are not simply what can happen this year or next, but the path and capacities will be available for the abuses of future administrations, officials, and transient social whims in a way that can create deep harm to those who may not meet the demands of the day, or who may be seen as deviant from the norm.<br/><br/>Some lives can no doubt be saved through the use of new technologies. But the question must be asked if it&#39;s worth the cost to society as a whole. In my mind, the answer is a clear no.",
1,DHS-2021-0015-0126,Comment Submitted by Anonymous,I have a camera or two facing me right now.  What judge won&#39;t say yes to a blanket warrant to view everyone&#39;s phone within a radius of a crime?  Is this country ready to decide cases based on places of privacy vs nature of a crime?  ,
1,DHS-2021-0015-0120,Comment Submitted by Parker Kay,"When you say &quot;emerging technology&quot;, I assume you mean facial recognition. This is my response to that.<br/>Facial recognition is not alright. Privacy is a basic human right, and facial recognition, while incredibly useful, on a mass scale is an absurd invasion of privacy. There is not necessarily a problem with facial recognition, but how it is used, and with consideration, I personally don&#39;t believe any governmental body can be trusted to not abuse this power.<br/>This also applies to most other forms of surveillance, including spyware, hacking, drone surveillance.<br/>I&#39;d like to think these points are important to make so much to the point that I, a twelve year old who has yet to graduate middle school, can understand the need for a right to privacy.<br/>",
1,DHS-2021-0015-0169,Comment Submitted by Matt Wheat,"Facial recognition technology while useful, is not appropriate for use by the federal government and will further erode the ability for persons to be anonymous in society. ",
1,DHS-2021-0015-0143,Comment Submitted by Jesus Delgado,"Facial recognition and AI is extremely scary, specially if it gets in the hands of the wrong people. <br/><br/>There is a very fine line between being useful for solving my a crime and being violation of a privacy and constitutional rights. ",
1,DHS-2021-0015-0172,Comment Submitted by Anonymous,"I don&#39;t feel comfortable with AI/Facial Recognition due to it being rife for abuse and racial profiling, along with it being able to be used in an authoritarian matter to target protestors. Everyone should not be surveilled just because there are SOME bad people out there. <br/><br/>Current facial recognition technology is not accurate at recognizing people of color, which could lead to many wrongful arrests. Facial recognition technology is used in authoritarian governments to control their citizens (such as punishing jaywalkers) and to surveil and intimidate political dissidents. It tips the balance of power way too much away from citizens. <br/><br/>This also gives too much power to individual government employees who may use it for personal reasons (which we know is already done in agencies such as the NSA despite it being against the rules https://www.reuters.com/article/us-usa-surveillance-watchdog-idUSBRE98Q14G20130927). Regardless of whatever rules are set today, it is a Pandora&#39;s box I don&#39;t trust being opened.<br/><br/>I also have concerns on how long this data will be kept. Just as we should have a right to be forgotten on the internet from private companies, our data should not be kept for decades and potentially be used against us years after the fact. <br/><br/>I don&#39;t trust this data will be kept private. It could be sold later in the future to companies or it could be stolen by hackers after breaching security. <br/><br/>I don&#39;t want Facial Recognition or AI surveillance at all. It should be highly limited, narrowly scoped, and heavily regulated, or not used at all.",
1,DHS-2021-0015-0135,Comment Submitted by Anonymous,"Facial recognition is invasive and unnecessary, plus the technology is still in infancy and prone to false positives. There&#39;s significant evidence that facial recognition software is much worse at identifying POC over white people, which could let to an increase in innocent convictions. At no point should computers be allowed to make the final call about identification for any American. Totally against this become a normal thing",
1,DHS-2021-0015-0133,Comment Submitted by Anonymous,"Facial recognition technology and AI profiling fundamentally violate the individual&#39;s right to privacy and enable discriminatory actions. This makes employing such techniques unconscionable when they can be used to violate individual rights. While not illegal yet, federal agencies have a responsibility to ensure such technologies are employed sparingly and only when these rights are not violated/when profiling would not be a concern.",
1,DHS-2021-0015-0141,Comment Submitted by Anonymous,"I do not wish to see my tax dollars fund the use of facial recognition of US citizens. Please cease any such program. We need more privacy, not less.",
1,DHS-2021-0015-0145,Comment Submitted by Alex Silver,"This is a horrible idea. The fact that the lead can be considered not buried only on a technicality leads me to believe that you knew this was going to be incredibly unpopular. What is this back alley tactic? When you eventually go live with the results, make sure to note the actual percentages of those for and against this.<br/><br/>I&#39;m sure some of you reading this understand that we came very close to a coup in this country not even a year ago. Do you really think another presidency like that should have access to a weapon as dangerous as this? ",
1,DHS-2021-0015-0159,Comment Submitted by Anonymous,"Trusting artificial intelligence to do such a job seems pretty sketchy. I don&#39;t believe AI can be controlled properly.<br/><br/>I also believe this is a violation of our privacy rights. Seems like facial recognition technology will try and track where we&#39;re going, what we&#39;re doing, etc. and seems to be like a sort of electronic surveillance conducted against private US citizens. The implementation of an AI to constantly search out and identify individuals is not something I agree with.",
1,DHS-2021-0015-0114,Comment Submitted by Anonymous,I don&#39;t see how facial recognition could be used in law enforcement without infringing on the privacy of Americans.,
1,DHS-2021-0015-0128,Comment Submitted by Sean Mack,"The potential of Artificial Intelligence certainly holds benefits to society, especially in a country in which inequity is a reality for many. However, I hold great concern over the fact that the companies that have invested the most time, money, and research into these technologies (Facebook, Google, etc.) are for-profit enterprises that have conducted a great deal of unethical business that has contributed to serious problems in regards to democracy and privacy. To think that the U.S. government would use this AI to power and improve facial recognition software is of serious concern, especially considering surveillance programs like Prism have already invaded personal privacy to such a great extent. Beyond this, I hold great concern that a majority of U.S. lawmakers do not have an understanding of the impacts artificial intilligence has on society. As the technology evolves quickly (alongside quantum computing), I think the ability to regulate this technology will move further and further out of reach.",
1,DHS-2021-0015-0140,Comment Submitted by Anonymous,"I do not wish to see my tax dollars fund the use of facial recognition of US citizens. Please cease any such program. We need more privacy, not less.",
1,DHS-2021-0015-0153,Comment Submitted by Anonymous,The government should take care to not blindly trust facial recognition software and to not unduly log facial data without permission or salient reason. Also I would warn against using 3rd party companies to store relevant data that could be hacked and used for nefarious purposes.,
1,DHS-2021-0015-0163,Comment Submitted by Michael Garvey,"As someone who works in aviation and deals with the TSA daily, and as an American patriot who values the work of the Department of Homeland Security I absolutely do NOT think the use of facial recognition is a good idea. Collection of data and metadata on American citizens is a ridiculous overreaching act of pointless futility which will only lead to bad things. Do not use AI facial recognition to compile data on the citizens of our country. Instead, let&rsquo;s focus on issues we can actually fix and make our nation better together. ",
1,DHS-2021-0015-0168,Comment Submitted by Anonymous,I am extremely against the use of facial recognition. No government agency is trustworthy enough to have that kind of power.,
1,DHS-2021-0015-0182,Comment Submitted by Anonymous,This is a huge invasion of privacy and is the foundation of social profiling technologies used by regimes like China.<br/>It won&#39;t really benefit the law enforcement as criminals will start wearing full face masks...,
1,DHS-2021-0015-0173,Comment Submitted by Anonymous,Facial recognition technology is a moral evil.,
1,DHS-2021-0015-0180,Comment Submitted by Brandyn Gabel,"Any form of computer program will have inherent issues. There is no such thing as a bug-free program, and using a program to identify people based on their face is a disaster waiting to happen. It&rsquo;s also an invasion of privacy because that means you&rsquo;re keeping records of people&rsquo;s faces who never consented to having their picture taken or their face analyzed. I think your face is covered under the fourth amendment: &ldquo; The right of the people to be secure in their persons, houses, papers, and effects, against unreasonable searches and seizures, shall not be violated&hellip;&rdquo; recording people&rsquo;s faces and analyzing them without permission is both a violation of an individual&rsquo;s right to their person and their effects. ",
1,DHS-2021-0015-0011,Comment Submitted by Paul Daily,"Hello DHS, <br/><br/>I understand you have a limited time to read this and so I will be be making statements here that I can back up, and that you can back up with a quick internet search. For brevity, I have omitted several sources. <br/> <br/>As a US Citizen, I feel that use of facial recognition on everyone without prior suspicion of a crime is a gross overreach of unwarranted searches. Even if one person in a crowd of 100 is a suspect to a crime, to submit 99 innocent people to a search unwarranted should be considered a violation of the fourth amendment to the US Constitution. <br/><br/>Furthermore, I feel that the suppression of our rights at the Borders of the USA should be found unlawful. More than two thirds of the US population lives within 100 miles of a US border essentially giving the DHS the power to unlawfully detain people indefinitely and seize property with minimal justification. The DHS appears to have constructed a set of rules made in a time of great fear that continue to obstruct the daily life, liberty, and pursuit of happiness of the citizens it is supposed to protect. <br/><br/>Facial Recognition is bad, not only is the false positive rate too high for anyone that isn&#39;t a white male between 18 and 40, but it&#39;s bad because you are building a database of faces and time-stamping locations where those faces were. It isn&#39;t just the person&#39;s face you are collecting here. You&#39;re collecting a map of everyone and where they are and at what time. They aren&#39;t a suspect of any crime when you collect this information, but if they do become a future suspect, you have all of this prior searched material ready to share. <br/><br/>The next thing to worry about is the security of the data. You&#39;re creating a honeypot in a world full of bears and badgers ready to break in. We saw the damage from the Philadelphia ALPR (Automated License Plate Reader) database leak which allowed stalkers to track individuals based on prior vehicle movements. We&#39;ve seen the breaches that happen to third party government contractors trusted to hold secrets. RSA was hacked once and that was pretty bad. This data isn&#39;t going to be secure. You may feel I&#39;m being dramatic, but people may die from it leaking. <br/><br/>I do not feel like the cost associated with buying more theatrical props for the border patrol/ TSA/ and DHS to play with is worth the taxpayer dollars that you are trying to spend on it.  ",
1,DHS-2021-0015-0010,Comment Submitted by Anonymous,"No, stop infringing on my rights. ",
1,DHS-2021-0015-0007,Comment Submitted by Anonymous,"I think technologies like facial recognition are a good tool in cracking down on crime. In terms of concerns about privacy, I think implementing a time limit on how long video using AI could be kept would be a good idea, and obviously it should be the dedicated job of some people to protect this data. Ultimately though we have a big problem with crime right now and we need to protect ourselves.",
1,DHS-2021-0015-0218,Unrelated Comment Submitted by Norf Koreuh,DHS,
1,DHS-2021-0015-0219,Comment Submitted by American Civil Liberties Union,"The American Civil Liberties Union writes in response to the 
Department of Homeland Security Science & Technology Directorate’s (S&T) 
information collection request regarding the creation of a survey to assess 
public opinion about its use of “AI in general and facial recognition in 
particular,” including for functions such as “customs and border protection, 
transportation security, and investigations” where it states it has already 
piloted such technology.
The ACLU opposes any efforts by DHS to expand its use of facial 
recognition technology. DHS’s contemplated survey is premised on the belief 
that if the Department could just “understand[] how the public perceives 
these technologies,” it could “gain[] public support for DHS’s use of these 
technologies.” 86 Fed. Reg. 61285. However, the problem with DHS’s use of 
facial recognition technology is not an insufficient understanding of how 
unpopular it is; the problem is that law enforcement use of facial recognition 
technology causes serious harm by leading to racially disparate arrests and 
investigations and facilitating pervasive government surveillance. 
A survey is quite unnecessary. DHS already has access to a long and 
well-documented public record — consisting of news articles and editorials, information from civil society,
 academic research, government research,
expert testimony,
 congressional debates,public comments, as well as firsthand accounts8 — regarding problems posed by facial recognition technology
and artificial intelligence. Most notably with regard to facial recognition
technology, the extensive record details the harms that are abiding and 
intrinsic to the technology, both when it fails and when it works. Facial 
recognition algorithms are well-known for having higher misidentification 
rates for Black people, people of color, women, and children, which has led to 
false arrests and mistaken incarceration.
Facial classification algorithms, which can purportedly be used to assess anything from an individual’s 
emotional state to their level of threat in a crowd, also suffer from serious —
and seriously biased — error rates.
10 Concerns would persist even if these 
issues were resolved: an expanded apparatus of facial recognition technology 
makes possible a totalizing and inescapable network of mass surveillance, 
which poses irreconcilable threats to constitutional freedoms including
freedom of association and speech, due process protections, and privacy. Any 
expansion of DHS’s use of facial recognition technology is untenable and 
dangerous.
DHS’s own deployments of facial recognition technology underscore 
the urgency and seriousness of these concerns. Its deployments have been 
plagued by data breaches, complaints that U.S citizens are not adequately 
informed of their right to opt out and that opt-outs for U.S. citizens are not 
honored in practice concerns that biometric pilot programs open the door to
hidden checkpoints and watchlists,
 and outcry about the Department’s use of the highly controversial face surveillance vendor Clearview AI,14 among 
other issues. DHS appears to be aware of these problems, but a survey is not 
the way to address well-founded public opposition to its deployment of facial 
recognition and artificial intelligence technology. Rather, the Department 
must actually grapple with the foundational problem of racism and pervasive 
surveillance posed by its use of the technology. 
Rather than gather self-justifying survey data, DHS should cease all 
efforts to expand deployment of facial recognition technology, and take to 
heart the already well-known concerns about the technology",
1,DHS-2021-0015-0221,Comment Submitted by International Biometrics + Identity Association,"Please see attached letter below. Thank you. <br/><br/> &mdash;Robert Tappan, Managing Director, International Biometrics + Identity Association, 1325 G Street, NW, Suite 500, Washington, DC  20005 On behalf of the International Biometrics + Identity Association (IBIA) and its 
membership, we are pleased to submit this letter to OIRA, to be included in the Request 
for Comments for the Department of Homeland Security’s Science and Technology 
Directorate (DHS S&T) and their Information Collection Request (ICR) to the Office of 
Management and Budget (OMB) regarding “Public Perceptions of Emerging Technologies” 
(Docket No. DHS-2021-0015).
The IBIA is the leading advocate and voice for the biometrics and identity technology 
industry. We advance the adoption and responsible use of technology-based identification 
solutions to enhance security and privacy, to confirm human identity, and to facilitate 
convenience and productivity for government, businesses and consumers. To carry out our 
mission effectively, IBIA focuses on three core activities: advocacy, engagement, and 
education.
We are grateful for the opportunity to comment on the proposed collection of information, 
especially as it relates to public opinion surrounding these important and critical 
applications — technologies that enhance personal identity and identification, shield 
financial transactions, prevent fraud, secure our borders and help protect the integrity of 
computer networks around the world.
Comments Regarding DSH S&T’s Information Collection Request (ICR)
“DHS has already used or piloted AI-based technologies in several of its key functions, 
including customs and border protection, transportation security, and investigations. 
However, AI in general and facial recognition in particular are not without public 
controversy, including concerns about bias, security and privacy.
Therefore, understanding how the public perceives these technologies, and then designing 
and deploying them in a manner responsive to the public’s concerns, is critical in gaining 
support for DHS’s use of these technologies.” — from the Notice’s Summary section
In general, IBIA and its Membership support the overall approach that DHS proposes with 
regard to conducting opinion research (noted as a “survey” in the Summary section of the 
Notice) among the public, in order to assess their perceptions about “emerging 
technologies”, most notably, artificial intelligence (AI) and facial recognition (FR). 
We acknowledge that many people have concerns about security, privacy and potential bias 
in some biometric technologies, some of which are rooted in a wide variety of information 
sources — some from facts-based analysis, and other sources that are far from accurate or 
based on purposeful misinformation.
Understanding and assuaging the public’s concerns about AI and FR technologies is a 
priority for IBIA and its members. The goal is to work towards making the public feel more 
secure, while at the same time endeavor to make continuous improvements to make these 
technologies better and more accurate, and therefore more trustworthy and secure. No 
technology is ever 100 percent correct all of the time. Certainly, some biometric 
technologies have issues that need to be continuously refined and improved. Nevertheless, 
biometric technologies are far superior in accuracy overall compared to unassisted human 
assessment.
As technologies continue to evolve and become more precise and accurate, IBIA and its 
Members also agree that robust, accurate and education-focused communications with the 
general public about the technologies in question is also an equally important objective. It is 
incumbent upon DHS, as well as its suppliers and manufacturers of these technologies, to 
assiduously and broadly educate the public and other key audiences about the advantages 
and security that is afforded by identity technologies. A poll undertaken by The Pew 
Foundation in the recent past cited that just 25% of Americans were aware of what 
biometrics are and how they are implemented or applied.
Comments regarding the questions posed in the “Supplementary Information” 
Section of the Notice
While we are supportive of the overall approach and purpose of the proposed survey, we 
also want to make several points and recommendations regarding the details about the 
composition, and number of respondents, as well as the survey’s methodology.
First, we would like to recommend, respectfully, that the sample size of individuals in this 
Information Collection Request be “statistically significant” — that is, a sample of a larger 
magnitude than has been suggested in the ICR. The 3,000 respondents cited by DHS in 
the Notice only represent a mere .0016 % of the total adult population of 258.3 million 
people in the United States (2020 Census).
What form will the Survey take? Presumably a telephone poll/survey, based on the number 
of respondents and the number of hours in the estimate of burden. In addition to 
recommending a larger number of respondents for this survey, we also would recommend 
that the exercise encompass a mixture of both quantitative and qualitative research, in order 
to better assess nuances in public opinion about AI and FR biometric technologies. 
DHS is especially interested in public comment addressing the following issues. The 
questions posed are: 
Q: Is this collection necessary to the proper functions of the Department?
IBIA Response: Yes. It is helpful and useful for DHS to seek periodic feedback and gauge 
public opinion on the nature and usage of these types of technologies, in order to better 
communicate why and how these technologies are being used, along with the benefits to US 
citizens, travelers, cybersecurity, financial transactions, law enforcement, etc. 
Q: Will this information be processed and used in a timely manner?
IBIA Response: The survey should be done in an expeditious manner, consistent with the 
appropriate methodolog(ies) being used to gather opinions and perceptions from the public. 
Q: Is the estimate of burden accurate? 
IBIA Response: Please refer to our thoughts above about sample size of respondents. In 
addition, what is the intended sample make-up? Other factors to consider: will it take into 
account geographic/racial/gender differences ? Prior exposure to biometric technologies?
Q: How might the Department enhance the quality, utility, and clarity of the 
information to be collected? 
IBIA Response: As mentioned earlier, in addition to increasing the number of respondents, 
our overall recommendation is that the sample be geographically, racially, and gender 
diverse. Also, as mentioned earlier, quantitative (internet/in-person/telephone polling) and
qualitative research (focus groups) would be optimal in capturing more nuanced and 
granular public opinion feedback.
Q: How might the Department minimize the burden of this collection on the 
respondents, including through the use of information technology? 
IBIA Response: Internet polling/opinion research could streamline and widen the number 
of responses from the public in a cost-effective manner. 
Thank you again for allowing IBIA the opportunity to submit these comments to OIRA 
regarding this ICR. We are aware — and embrace — that our organization’s written 
comments in response to this Notice will be considered part of the public record. Please do 
not hesitate to contact us if we can provide any further guidance or recommendations 
regarding these issues",
1,DHS-2021-0015-0225,Comment Submitted by Anonymous,"to whoever federal agent is reading this i was just having fun lol. good luck with your job i&#39;m sure its stressful.<br/><br/>anywho i personally think that you probably should stop collecting data on citizens who don&#39;t have any violations, or are suspected of commuting any. personally i think your database should be set up as follows if you where to do any restructuring of the system or anything of the likes:<br/><br/>profiles for every person being recorded with all  off it locked where no one can access it without a key. the key being a warrant of suspicion on a suspect and the only other way to open it is to sweep the entire database for something that you need to locate without showing who it is without a search key. for all i know though this could be how it is and im not a security expert but its just my two cents. <br/><br/>i personally find it funny that if the rumors are true that it means your database is full of records of people looking at promiscuous images and whatnot.<br/><br/>also if you do record peoples searches can you release a list of the most common searched terms collected each year. this wouldn&#39;t be a breach of security because no names or anything would be attached, just a list of words/phrases, and various inquiry,  and how many times searched on the internet. that would be pretty neat to look at i think.  i have always heard the rumors of it automatically putting a thing on you to monitor your online activity.  <br/><br/>",
1,DHS-2021-0015-0009,Comment Submitted by Anonymous,"The incompetence, bullying, and unaccountable bureaucracy at work at DHS, CBP, BP, and OFO make it clear to me that under no circumstances would I want these nitwits taking pictures of anyone or having access to cloud and external servers full of personal identifiers.  Homeland Security is turning into a federal police force with military grade equipment, and they are deploying their personnel to combat domestic protests and protect monuments!  No way do I want them having access to this type of technology. ",
1,DHS-2021-0015-0006,Comment Submitted by Bredemarket,"I have provided my comments (see attached file) on the referenced Information Collection Request (ICR) from two perspectives.<br/>1.<span style='padding-left: 30px'></span>As a U.S. citizen who uses airlines and other public transportation to travel both within and outside of the United States.<br/>2.<span style='padding-left: 30px'></span>As the sole proprietor of the consulting firm Bredemarket, providing marketing and writing services to identity/biometrics firms, including firms that do business with the Department of Homeland Security and other government agencies involved in (quoting from the ICR) &ldquo;customs and border protection, transportation security, and investigations.&rdquo; At the same time, as an independent sole proprietor I am free of the influence of any individual identity vendor and can address identity issues without reservation. <br/>I hope that these comments will benefit the Department of Homeland Security and the broader community.",
1,DHS-2021-0015-0012,Duplicate Comment Submitted by Paul Daily,"To Whom It May Concern: I have provided my comments on the referenced Information Collection Request (ICR) from two perspectives. 1. As a U.S. citizen who uses airlines and other public transportation to travel both within and outside of the United States. 2. As the sole proprietor of the consulting firm Bredemarket, providing marketing and writing services to identity/biometrics firms, including firms that do business with the Department of Homeland Security and other government agencies involved in (quoting from the ICR) “customs and border protection, transportation security, and investigations.” At the same time, as an independent sole proprietor I am free of the influence of any individual identity vendor and can address identity issues without reservation. I hope that these comments will benefit the Department of Homeland Security and the broader community. Comments begin on the following page. Page 1 of 8
November 10, 2021
Re: Bredemarket comments on DHS-2021-0015-0005, Information Collection Request, Public 
Perceptions of Emerging Technology
Submitted to https://www.regulations.gov/document/DHS-2021-0015-0005
To Whom It May Concern:
I have provided my comments on the referenced Information Collection Request (ICR) from two 
perspectives.
1. As a U.S. citizen who uses airlines and other public transportation to travel both within 
and outside of the United States.
2. As the sole proprietor of the consulting firm Bredemarket, providing marketing and 
writing services to identity/biometrics firms, including firms that do business with the 
Department of Homeland Security and other government agencies involved in (quoting 
from the ICR) “customs and border protection, transportation security, and 
investigations.” At the same time, as an independent sole proprietor I am free of the 
influence of any individual identity vendor and can address identity issues without 
reservation. 
I hope that these comments will benefit the Department of Homeland Security and the broader 
community.
Comments begin on the following page. 
Sincerely,
John E. Bredehoft
Bredemarket
Attachment: Bredemarket comments on DHS-2021-0015-0005, Information Collection Request, 
Public Perceptions of Emerging Technology
Bredemarket DHS-2021-0015-0005 Comments
Page 2 of 8
Bredemarket https://bredemarket.com/
Bredemarket comments on DHS-2021-0015-0005, Information 
Collection Request, Public Perceptions of Emerging Technology 
Selected text from the original Information Collection Request (ICR) appears in blue italic text, 
followed by my responses 
Contents
Bredemarket comments on DHS-2021-0015-0005, Information Collection Request, Public Perceptions of 
Emerging Technology....................................................................................................................................2
Bias, Security, and Privacy (Summary)......................................................................................................2
A world without biometric collection is a world with increased bias and less security and privacy 
(question 1)...............................................................................................................................................5
Biometrics enhances accuracy without adversely impacting timeliness (questions 2 and 3)..................6
The benefits of continuous improvement (questions 4 and 5) ................................................................7
The dangers of removing facial recognition and AI from DHS solutions..................................................7
Bias, Security, and Privacy (Summary)
(from the Summary) AI in general and facial recognition in particular are not without public 
controversy, including concerns about bias, security, and privacy.
While DHS did not explicitly request comments on the Summary, the topics of bias, security, 
and privacy deserve attention. Public misunderstandings on these topics have the capability of 
scuttling all of DHS’ efforts in customs and border protection, transportation security, and 
investigations
Regarding bias, it is imperative upon government agencies, biometric vendors, and other 
interested parties (including myself as a biometric consultant) to educate and inform the public 
about issues relating to bias. In the interests of brevity, I will confine myself to two critical points.
• There is a difference between identification of individuals and classification of 
groups of individuals. 
o Most of the public was introduced to the topic of biometric bias via the 2018 study 
Gender Shades (at the 
http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf URL). 
Unfortunately, the popular descriptions of this study confused several issues. 
o The summary at the top of the Gender Shades website http://gendershades.org/
clearly frames the question asked by the study: “How well do IBM, Microsoft, and 
Face++ AI services guess the gender of a face?” As the study title and its 
summary clearly state, the study only attempted to classify the genders of faces. 
Bredemarket DHS-2021-0015-0005 Comments
Page 3 of 8
Bredemarket https://bredemarket.com/
o This is a different problem than the problem addressed in customs and border 
protection, transportation security, and investigations applications: namely, the 
identification of an individual. If someone purporting to be me attempts to board a 
plane, DHS does not care whether I am male, female, gender fluid, or anything 
else related to gender. DHS only cares about my individual identity. 
o It is imperative that any discussion of bias as related to DHS purposes confine 
itself to the DHS use case of identification of individuals. 
• Different algorithms exhibit different levels of bias (and different types of bias) 
when identifying individuals.
o While Gender Shades did not directly address this issue, it turns out that it is 
possible to identify differences in individual identification between different 
genders, races, and ages. 
o The National Institute of Standards and Technology (NIST) has conducted 
ongoing studies of the accuracy and performance of face recognition algorithms. 
In one of these tests, the FRVT 1:1 Verification Test (at the 
https://pages.nist.gov/frvt/html/frvt11.html URL), each tested algorithm is 
examined for its performance among different genders, races (with nationality 
used as a proxy for race), and ages. 
o While neither IBM nor Microsoft (two of the three algorithm providers studied in 
Gender Shades) have not submitted algorithms to the FRVT 1:1 Verification 
Test, over 360 1:1 algorithms have been tested by NIST. 
o In a 2019 report issued by NIST on demographic effects (at the 
https://nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8280.pdf URL), NIST concluded 
that the tested algorithms “show a wide range in accuracy across developers, 
with the most accurate algorithms producing many fewer errors.”
o It is possible to look at the data for each individual algorithm to see detailed 
information on the algorithm’s performance. For example, here is the data from 
one algorithm (CLEARVIEWAI_000) for six national origins (used as a proxy for 
race), five age ranges, and three types of gender comparisons (male to female, 
male to male, and female to female). In general, dark blue results are the most 
accurate. 
Bredemarket DHS-2021-0015-0005 Comments
Page 4 of 8
Bredemarket https://bredemarket.com/
From https://pages.nist.gov/frvt/reportcards/11/clearviewai_000.html
o However, even NIST tests are just that – tests. Performance of a research 
algorithm on a NIST test with NIST data does not guarantee the same 
performance of an operational algorithm in a DHS system with DHS data. 
o As DHS implements biometric systems for its purposes of customs and border 
protection, transportation security, and investigations, DHS not only needs to 
internally measure the overall accuracy of these systems using DHS algorithms 
and data, but also needs to internally measure accuracy when these 
demographic factors are taken into account. While even highly accurate results 
may not be perceived as such by the public (the anecdotal tale of a single 
inaccurate result may outweigh stellar statistical accuracy in the public’s mind), 
such accuracy measurements are essential for the DHS to ensure that it is 
fulfilling its mission. 
Regarding security and privacy, which are intertwined in many ways, there are legitimate 
questions regarding how the use of biometric technologies can detract or enhance the security 
and privacy of individual information. (I will confine myself to technology issues, and will not 
comment on the societal questions regarding knowledge of an individual’s whereabouts.)
• Data, including facial recognition vectors or templates, is stored in systems that may 
themselves be compromised. This is the same issue that is faced by other types of data 
that may be compromised, including passwords. In this regard, the security of facial 
recognition data is no different than the security of other data.
• In some of the DHS use cases, it is not only necessary to store facial recognition vectors 
or templates, but it is also necessary to store the original facial images. These are not 
needed by the facial recognition algorithms themselves, but by the humans who review 
the results of facial algorithm comparisons. As long as we continue to place facial 
images on driver’s licenses, passports, visas, and other secure identity documents, the 
need to store these facial images will continue and cannot be avoided. 
• However, one must ensure that the storage of any personally identifiable information 
(including Social Security Numbers and other non-biometric data) is secure, and that the 
PII is only available on a need-to-know basis. 
Bredemarket DHS-2021-0015-0005 Comments
Page 5 of 8
Bredemarket https://bredemarket.com/
• In some cases, the use of facial recognition technologies can actually enhance privacy. 
For example, take the moves by various U.S. states to replace their existing physical 
driver’s licenses with smartphone-based mobile driver’s licenses (mDLs). These mDL 
applications can be designed to only provide necessary information to those viewing the 
mDL. 
o When a purchase uses a physical driver’s license to buy age-restricted items 
such as alcohol, the store clerk viewing the license is able to see a vast amount 
of PII, including the purchaser’s birthdate, full name, residence address, and 
even height and weight. A dishonest store clerk can easily misuse this data.
o When a purchaser uses a mobile driver’s license to buy age-restricted items, 
most of this information is not exposed to the store clerk viewing the license. 
Even the purchaser’s birthdate is not exposed; all that the store clerk sees is 
whether or not the purchaser is old enough to buy the restricted item (for 
example, over the age of 21). 
o Therefore, use of these technologies can actually enhance privacy. 
A world without biometric collection is a world with increased bias and less security and 
privacy (question 1)
(from Supplementary Information) DHS is especially interested in public comment addressing 
the following issues: 
(1) Is this collection necessary to the proper functions of the Department; 
Because of many factors, including the 9/11 tragedy that spurred the organization of DHS itself, 
DHS has been charged to identify individuals as a part of its oversight of customs and border 
protection, transportation security, and investigations. There are many ways to identify 
individuals, including:
• What you know, such as a password.
• What you have, such as a passport or token.
• What you are, such as your individual face, fingers, voice, or DNA. 
• Where you are. 
Is it possible to identify an individual without use of computerized facial recognition or other
biometric or AI technologies? In other words, can the “what you are” test be eliminated from 
DHS operations?
Some may claim that the “what you have” test is sufficient. Present a driver’s license or a 
passport and you’re identified. However, secure documents are themselves secured by the use 
of biometrics, primarily facial recognition. Before a passport is issued, many countries including 
the U.S. conduct some type of biometric test to ensure that a single person does not obtain two 
or more passports. Similar tests are conducted before driver’s licenses and other secure 
documents are issued. In addition, people attempt to forge secure documents by creating fake 
driver’s licenses and fake passports. 
In short, there is no way to remove biometric identification from the DHS identification operation. 
Bredemarket DHS-2021-0015-0005 Comments
Page 6 of 8
Bredemarket https://bredemarket.com/
Biometrics enhances accuracy without adversely impacting timeliness (questions 2 and 3)
(2) will this information be processed and used in a timely manner; 
I am answering this question from the perspective of a person crossing the border or boarding a
plane. From this perspective, you can ask whether the use of biometric technologies makes the 
entire process faster, or slower. 
• Before biometric technologies became available, a person would cross a border or board 
a plane either by conducting no security check at all, or by having a human conduct a 
manual security check using the document(s) provided by an individual. 
o Unless a person was diverted to a secondary inspection process, the 
identification of the person (excluding questions such as “What is your purpose 
for entering the United States?”) could be accomplished in a few seconds.
o However, manual security checks are much less accurate than technological 
solutions, as will be illustrated in response to question 5 below. 
• With biometric technologies, it is necessary to measure both the time to acquire the 
biometric data (in this case a facial image) and the time to perform the comparison of the 
acquired data against the known data for the person (from a passport, passenger 
manifest, or database). 
o The time to acquire biometric data continues to improve. In some cases, the 
biometric data can be acquired “on the move” as the person is walking toward a 
gate or other entry area, thus requiring no additional time from the person’s 
perspective.
o The time to compare biometric data can vary. If the source of the known data 
(such as the passport) is with the person, then comparison can be instantaneous 
from the person’s perspective. If the source of the known data is a database in a 
remote location, then the speed of comparison depends upon many factors, 
including network connections and server computation times. Naturally, DHS 
designs its systems to minimize this time, ensuring minimal or no delay from the 
person’s perspective. Of course, a network or system failure can adversely affect 
this. 
o In short, biometric evaluation is at fast if not faster than manual processes 
(provided no network or system failure occurs), and is more accurate than human 
processes. 
(3) is the estimate of burden accurate; 
Again answering from the perspective of a person crossing the border or boarding a plane, and 
excluding operations outside of the scope of DHS (such as the tasks necessary to obtain a 
passport, visa, or driver’s license), the burden upon the traveler is minimal for the reasons 
stated in response to question 2. 
Bredemarket DHS-2021-0015-0005 Comments
Page 7 of 8
Bredemarket https://bredemarket.com/
The benefits of continuous improvement (questions 4 and 5)
(4) how might the Department enhance the quality, utility, and clarity of the information to be 
collected; and 
When I was an employee of MorphoTrak (now part of IDEMIA), I had the privilege of 
participating in a visit to the San Diego-Tijuana border area, sponsored by the International 
Biometric + Identity Association (IBIA). As part of this visit, I was privileged to view a test at Otay 
Mesa of various biometric acquisition methods. This was part of DHS’ ongoing efforts to 
improve the biometric information collection process and ensure that quality data was captured 
at minimal burden to travelers. 
Another example of DHS efforts to enhance information collect is the annual Biometric 
Technology Rallies. 
(5) how might the Department minimize the burden of this collection on the respondents, 
including through the use of information technology?
DHS is already working to minimize these burdens, both by monitoring the activities of other 
government agencies such as NIST, and by its own efforts outline in question 4. 
DHS can continue to address these burdens in other areas, such as by conducting its own bias 
measurements on DHS algorithms and DHS data as outlined in response to question 1. 
The dangers of removing facial recognition and AI from DHS solutions
Of course, even the best efforts of DHS will not satisfy some members of the public. I anticipate 
that may of the respondents to this ICR will question the need to use biometrics to identify 
individuals, or even the need to identify individuals at all, believing that the societal costs 
outweigh the benefits. But before undertaking such drastic action, the consequences of 
following these alternative paths must be considered. 
Taking an example outside of the non-criminal travel interests of DHS, some people prefer to 
use human eyewitness identification rather than computerized facial recognition. However, 
eyewitness identification itself has clear issues of bias. The Innocence Project has documented 
many cases in which eyewitness (mis)identification has resulted in wrongful criminal convictions 
which were later overturned by biometric evidence. 
Bredemarket DHS-2021-0015-0005 Comments
Page 8 of 8
Bredemarket https://bredemarket.com/
“Mistaken eyewitness identifications contributed to approximately 69% of the 
more than 375 wrongful convictions in the United States overturned by postconviction DNA evidence.
“Inaccurate eyewitness identifications can confound investigations from the 
earliest stages. Critical time is lost while police are distracted from the real 
perpetrator, focusing instead on building the case against an innocent person.
“Despite solid and growing proof of the inaccuracy of traditional eyewitness ID 
procedures – and the availability of simple measures to reform them – traditional 
eyewitness identifications remain among the most commonly used and 
compelling evidence brought against criminal defendants.”
Innocence Project, Eyewitness Identification Reform, 
https://innocenceproject.org/eyewitness-identification-reform/
Do we really dump computerized artificial intelligence and facial recognition, only to end up with 
something that is even worse?",
1,DHS-2021-0015-0021,Comment Submitted by Jacob H,"Absolutely not. Never in a million years should this be allowed. AI and Facial recognition will not make us any safer, but will further erode our freedoms. No, no, no, a thousand times no",
1,DHS-2021-0015-0110,Comment Submitted by Anonymous,"Facial recognition technology unlawfully captures the biometric data of everyone who engages with it.  This is a violation of my right to privacy in the near-term, and presents a long-term violation of my freedoms of expression and privacy.  The government has no business monitoring mine, nor other&#39;s doing, without just cause.",
1,DHS-2021-0015-0117,Comment Submitted by Anonymous,Any application of the technologies mentioned (AI and Facial Recognition) is fundamentally unacceptable. Its far too risky.,
1,DHS-2021-0015-0124,Comment Submitted by Anonymous,Opposed due to privacy implications. ,
1,DHS-2021-0015-0132,Comment Submitted by K Gillette,"Study after study has documented the racial bias in AI recognition. And study after study has documented the racial bias in every level of our law enforcement and justice system. Combining these is a recipe for even worse racist outcomes, an unconscionable conflict with the &quot;created equal&quot; theme of our constitution.<br/><br/>Beyond that, tracking facial recognition grossly violates reasonable expectations of privacy and the ability to interact in the public sphere without fear of your very existence being treated as criminal.<br/><br/>As US citizen and a voter, I am vehemently opposed to any increased invasion of our rights to privacy and free movement. All levels of our government have way too much bias in their track record to be trusted with this additional power over policing the daily activity of our people. Fix the biases in the tools and systems you currently have before grabbing for a tool like this with so much risk of compounding bias and overreach.",
1,DHS-2021-0015-0167,Comment Submitted by Nate C,Using facial recognition on the public is a huge violation of privacy.<br/>Using AI technology to enhance such techniques is only worsening the violation.<br/><br/>,
1,DHS-2021-0015-0111,Comment Submitted by Anonymous,I don&rsquo;t like the idea because I&rsquo;m ugly yo ,
1,DHS-2021-0015-0150,Comment Submitted by Anonymous,Facial recognition AI is a gross violation of human rights to privacy and via its long term ramifications right to not live in a totalitarian dystopia. Do not. Do NOT. ,
1,DHS-2021-0015-0112,Comment Submitted by Lily Anderson,"I do not support the use of facial recognition or AI as a means of surveillance of the public. For one, I am concerned by the existing extent of mass surveillance as it exist today, and wish to see it reduced. I further think these are bad ideas as there are numerous stories of them providing misidentifications, while being inscrutable as to the cause of this shortcoming. Finally, these technologies cannot understand things such as human discretion, individual circumstances, and miscellaneous factors. ",
1,DHS-2021-0015-0115,Comment Submitted by Anonymous,"This is a terrible idea. The Electronic Frontier Foundation is already fighting against this. It is also won&#39;t add any capability, will cost too much, and will be abused.",
1,DHS-2021-0015-0130,Comment Submitted by Benjamin  Hauch,"Facial recognition and artificial is a blatant infringement of the constitutional rights of American Citizens. Any democratic government that imposes or allows the use of Facial recognition technology and artificial intelligence on its people for the sake of security, public or private, opens itself up to dissolution of its primary philosophy.  ",
1,DHS-2021-0015-0139,Comment Submitted by Anonymous,"There is nothing good that can come of testing AI and Facial recognition on citizens. The only thing that can possibly happen is unnecessary surveillance of citizens, and at worse it could lead to dangerous situations based on bad data. No one is ready to give up their privacy for testing, and nor should they.",
1,DHS-2021-0015-0142,Comment Submitted by Anonymous,"I don&#39;t trust facial recognition to work 100% of the time currently (based on what I&#39;ve heard). Even if it does it makes me uncomfortable to know that the government or corporations can track exactly where I go and form profiles on me like a surveillance state. At least with phones i can chose not to use it, though don&#39;t",
1,DHS-2021-0015-0151,Comment Submitted by Anonymous,"i think Ai and facial recognition are great tools and probably have usabiltiy in wide variety of fields, but not in goverment tracking or other surveilance systems. Another important issue should be who are we allowing to use this technology and are there going to misuse them.",
1,DHS-2021-0015-0109,Comment Submitted by Orion Torcellini,"It is my firm belief as an American citizen of this great state of Connecticut that the use of AI especially for uses of facial recognition will prove to be detrimental to the ability of the American people to live free and without draconian government overreach. Any attempt to institute the use of AI for ANY government applications of identification are immoral at best and Orwellian at worst. I therefore implore anyone reading this response to understand the gravity of the situation, and to think deeply about the implications of the decision you place before the American people. Do not allow us to tread down the same police state path as that of China and Russia, as a 24 year old your decisions will have broad reaching effects on the future of my life. Please ponder this",
1,DHS-2021-0015-0118,Comment Submitted by Trey Del Bonis,Aggressive overpolicing is one of the most major issues with government&#39;s enforcement of the law in the United States today.  Further granting police and other law enforcement agencies more tools to surveil our fellow citizens is yet another example of government overreach and the resources can be much more well-spent on programs that directly help people instead of furthering punitive goals.,
1,DHS-2021-0015-0122,Comment Submitted by Anonymous,"The usage of Ai and Facial Recognition in uage in security is a great idea;however, there should be a lot of limitations and permissions needed to be used. In terms of privacy, the AI and facial recognition is a complete nightmare. This technology should not be used in common and public areas such as stores, schools, etc. The technology should only in places of high value such as major federal buildings and only with the public statement plastered on the wall that the building is under AI and facial Recognition surveillance. Qe don&#39;t need a &quot;Big Brother&quot; watching over us all the time.",
1,DHS-2021-0015-0125,Comment Submitted by Erin Rowzee,"I am not comfortable with AI being used by the government or private businesses. It goes against my constitutional right to privacy. Everyone I know has no interest in AI being a part of my life. As the future progresses, true progressive people are learning to love the land again, value clean air and fight to drink clean water. ",
1,DHS-2021-0015-0137,Comment Submitted by Anonymous,Facial Recognition software/AI is inherently too unreliable to be trusted for any serious applications. People often change the way they look and there are always multiple people that look very similar to any one person. Keeping up with each person would be not only prohibitively resource-exhaustive but also an unacceptable invasion of privacy.,
1,DHS-2021-0015-0164,Comment Submitted by Anonymous,"The use of facial recognition contributes to the gradual erosion of privacy that we&#39;ve seen for most of our lives. There&#39;s no right to be private in public, and it&#39;s possible to be recognized, but there&#39;s a dramatic difference between being recognized by a person and being recognized through automated means.<br/><br/>The widespread deployment of facial recognition would mean that Americans would no longer be able to go out in public in relative anonymity, which we&#39;ve enjoyed in cities for all of our nation&#39;s history.<br/><br/>The right to privacy is not explicitly stated in the U.S. Constitution, but decisions such as Griswold v. Connecticut reflect that there is a general right to privacy implied by the Fourth Amendment as well as other passages and specific codified rights. The American public expects the government to protect our constitutional rights, and while the EU is enhancing privacy protections, our leaders instead seem to be intent on further eroding our privacy. You need only look to the Netherlands to find a jurisdiction where CCTV cameras are only allowed by permit, illegal in most contexts.<br/><br/>The widespread deployment of facial recognition would violate our right to privacy, violate the trust of the American public, and further erode America&#39;s image abroad. Thus, I am strongly opposed, and I believe there is no way to make the use of this technology acceptable.",
1,DHS-2021-0015-0171,Comment Submitted by Anonymous,AI and facial recognition technology needs to be regulated and used very judiciously. The risks far outweigh the potential benefits. There is too much potential for it to be turned against law abiding citizens. It&rsquo;s a violation of privacy and should be treated as an affront to basic human rights.,
1,DHS-2021-0015-0146,Comment Submitted by Jake Moody,"Facial Recognition should be treated in a similar vein as other biometric data collection and processing, such as fingerprints, medical history, DNA collection and so forth, where government collection can be obtained only through explicit permission from the judicial system, standard criminal processing, and or voluntary surrendering from said person.<br/><br/>Private industry should be allowed to offer the purchasing of biometric data from individuals, and should be required to always obtain direct, first-party permission for that data collection, unless individuals have explicitly volunteered that information for public access or for third-party transferring.<br/><br/>However, the government should not be allowed to utilize this information, even if the data is public or is allowed for purchase by the selling of third-parties, without the reiteration of consent from the first-party individual or  judicial system, as government entities have additional powers over said persons that those originating companies do not.<br/><br/>In regard to AI in general, it is to the country&rsquo;s moral and technological advantage to allow for the collection of as much data as possible, and the standard and regular deployment of data collection and data applications by all level of government should be prioritized. However, the LESS data the government and private sector are allowed to collect, the more, theoretically, efficient their learning models could develop to be, compared to mass collection and processing countries like China. So it may very well be to our advantage to LIMIT the available fuel for AI within the government, not merely for moral purposes, but for the sake of fostering superior technology. All of which should be made publicly available for private, civilian use, which does not undermine national security.",
1,DHS-2021-0015-0131,Comment Submitted by Anonymous,"It is too easy for anyone to gather identifying data and use it to track people illegally.  Facial recognition technology when used in this manner should be illegal. No one in the government can be trusted to use this technology 100% as intended by clear, level head, non america hating Americans. As the government is currently full of the creatures from &quot;the swamp&quot;, they should not be allowed anywhere near it. ",
1,DHS-2021-0015-0162,Comment Submitted by Anonymous,I am very opposed to this technology as it leads the way to even more increased surveillance than even the patriot act allowed.,
1,DHS-2021-0015-0013,Comment Submitted by Nun Ya,"Use of facial recognition technology is not in a place I would consider safe to the average citizen yet. All it takes is one malefactor to turn that information on it&#39;s head against users, not simply some hacker or foreign entity, although those certainly are an issue, but individuals within our own state department who operate off of the desire of selfish gain. We&#39;re in an era where our social media itself has just been outed as working to manipulate us all against each other, imagine what could happen with biometrics. As recent years and administrations have demonstrated quite clearly, our elected officials are not immune to corruption, nor taking advantage of said corruption for their own personal gain. <br/>At bare minimum, without a standalone third party whose mission statement is to be completely neutral and fair without the ability to be impacted by government influence, the collection, use and storage of this data runs the very real risk of pushing us in the direction of Communist China and its social credit system, nevermind more proactive and malicious uses of the technology.",
1,DHS-2021-0015-0073,Comment Submitted by Anonymous Citizen,"(1) AI tools are already understood to be, at the very least, inherently biased based on the data set from which they were trained. By nature, it is impossible to produce a facial recognition tool that is free from bias. Suggest this PBS documentary as a primer: https://www.pbs.org/independentlens/documentaries/coded-bias/<br/><br/>(2) DHS has limited oversight and essentially unchecked powers at border crossings. It is incentivized to use facial recognition technologies in ways that are unacceptable.<br/><br/>(3) My personal data was stolen by hackers as part of the OPM data breach in 2015 (https://en.wikipedia.org/wiki/Office_of_Personnel_Management_data_breach). DHS is absolutely not immune to a data breach of its own. Sensitive data generated by any kind of facial recognition capability will inevitably be stolen or otherwise misused, causing harm to the public. The only way to prevent such data from being misused is to not create it in the first place. DHS should look carefully at the costs incurred by the OPM hack before deciding to collect additional data.<br/><br/>(4) For what it&#39;s worth, my personal opinion is that the use of pervasive facial recognition in any setting is an invasion of privacy and an affront to human dignity, regardless of circumstances or perceived benefit. I don&#39;t want to live in a country that treats its citizens in such a way.<br/><br/>In summary, facial recognition tools are ultimately flawed, and DHS has demonstrated a clear and longstanding pattern of behavior that essentially precludes it from using such technologies responsibly. I would suggest that DHS look to states and municipalities that have banned facial recognition tools to find alternative ways of accomplishing its objectives.",
1,DHS-2021-0015-0044,Comment Submitted by Anonymous,"The &quot;Summary&quot; section of this notice states &quot;understanding how the public perceives these technologies, and then designing and deploying them in a manner responsive to the public&#39;s concerns, is critical in gaining public support.&quot;<br/><br/>As a member of the public, I can confidently say that the only way to gain my support for DHS use of facial recognition technology is for that technology to never, ever be deployed.<br/><br/>The massive vectors of abuse possible with facial recognition and associated artificial intelligence, coupled with the role DHS plays in our society and their track record with respect to civil liberties, leads me to the conclusion that there is no &quot;good&quot; or &quot;safe&quot; way to design and deploy this technology.",
1,DHS-2021-0015-0079,Comment Submitted by Anonymous,Facial recognition should be banned. Data obtained from humans is said humans property. ,
1,DHS-2021-0015-0098,Comment Submitted by Daniel Gopalan,I am concerned that these new technologies will violate our privacy and civil liberties. ,
1,DHS-2021-0015-0062,Comment Submitted by Anonymous,"I&#39;m extremely wary and concerned about any widespread or targeted implementation of facial recognition technology, powered/couples with AI or otherwise. AI has a documented bias towards minorities, and facial recognition fails regularly when faced with darker skin tones. Either of these failure states can be catastrophic for an individual&#39;s personal safety and liberty in the event of a false match.<br/><br/>Additionally, I have zero confidence in ability of the government to secure of any stored data. As facial recognition is rolled out to more and more spheres,  bad actors (hackers) will find it more and more tempting to steal and sell. Whether they exploit hardware, software, or personnel vulnerabilities, it is likely a matter of time before there is an Equifax level data breach, which could ruin people&#39;s lives and potentially prevent them from travel through no fault of their own.",
1,DHS-2021-0015-0068,Comment Submitted by Anonymous,I think this is a complete invasive practice and unconstitutional.,
1,DHS-2021-0015-0080,Comment Submitted by Anonymous,"As a data scientist myself, I can say that these emerging technologies are a dangerous tool to rely on, in attempting to predict crime. There are many ways data can be biased, just to start with. Collecting data from samples irrespective of the population will also introduce error. Models are not only imperfect, but also difficult to explain and understand. To rely on a model for anything truly serious and impactful is irresponsible. The most these models should do is suggest directions, and leads for crime. A great example of a complete failure to use data science as a tool to predict crime is the Pasco police department, which has violated citizens rights again and again in an attempt to prove that their &quot;data-driven&quot; approach is even slightly helpful. Using these methods to monitor and police our own citizens would be a complete moral failure, and a major issue for future generations, especially the people that will have to live through the launch. Please do not let this happen.",
1,DHS-2021-0015-0092,Comment Submitted by Dylan McCombs,"I wholeheartedly disapprove of the use of facial recognition technologies and related systems by any police or law enforcement group. Not only are they a gross violation of personal privacy that would be used without consent, but the potential for misuse is incredibly high, especially with the almost nonexistent regulations on these technologies under the law. Not only that, but these systems have been shown to often produce widely inaccurate results, which could lead to false arrests, incorrect suspect identification, and a slew of other issues that would actually make law enforcement more difficult and dangerous for both the officers and the citizens. <br/>In short, I would not even consider facial recognition technology as a viable law enforcement tool until it&#39;s much closer to perfected than at present, and even then i still have my misgivings. ",
1,DHS-2021-0015-0100,Comment Submitted by Zachary Minor,"I am a trained and certified digital forensics and cyber incident response investigator and computer security researcher with roughly a decade of experience, some of which includes working on AI systems in the private sector. <br/><br/>I am deeply concerned by the use of machine learning classification and regression modelling(artificial intelligence systems in common parlance) within the realm of law enforcement and defense. The nature of these systems is that you are attempting to distill correlations from a large data-set into a large system of automatically generated rules and patterns. Given the large size of these models and data sets, these are black box systems by nature, i.e. the creators cannot have a complete understanding of how the system actually works. As such, all work on and using these systems is empirically designed and fine-tuned. It is not theory driven beyond a very rudimentary level, all advances in the field are generally driven by results based experimentation. This presents a problem when we enter domains in which there is a public policy impact. There is no real way of rigorously proving that the system is fair, truly working towards public policy objectives, or without hidden variables. This presents both moral and practical problems. <br/><br/>On the moral side of the house, we have discrimination and privacy. The nature of large datasets includes many hidden variables, such as disparities in race, socioeconomic status and religious beliefs. White people, by nature of American demographics and socioeconomic factors, are more likely to have a drivers license, and the data-set of drivers license photos would otherwise make a convenient source from which to build a facial recognition machine learning algorithm. But if you were to use this data-set to build a facial recognition algorithm, you&#39;d end up with a system which is more tuned to the facial identifying factors of white people&#39;s faces thus generating a disparate impact. So too with different religions, whose drivers license photos may include religious headgear or hair making it harder for a machine to build patterns of recognition. So now we are left with a system which is more likely to falsely identify ethnic and religious minorities. And then there is the privacy component, the use of facial recognition in general involves the collection and processing of personally identifying information. While it is true that we already do this at border crossings and in many government agent-citizen interactions, feeding more personal information into computer systems(especially black box ones) by definition increases the risk that a bad actor will obtain this information. After all, when information is held in more places, there are more places from which it can be stolen and more work is needed to secure them. <br/><br/>Now onto the practical side of the house. Because of the black box nature of machine learning models, it is not possible to entirely audit them for effectiveness against edge cases and exploits. We cannot look at a list of every rule or pattern generated by a large facial recognition algorithm because to do so would require an inhuman amount of time, so we are left with automated fuzzy testing. This is inadequate to fully rule out certain exploits present in many machine learning models, especially large ones such as those which are used for image processing. It is possible to build a second machine learning model designed to beat the first one which can generate inputs in the forms of either digital or physical patterns(known as adversarial images) which, when fed into the target machine learning model, will induce failure or even worse, false conclusions. For example, a person entering the country under false documents who is a known person of interest could use a specially designed mask or makeup to fool the system into not recognizing them as a known foreign intelligence service asset. This need not be done in such an obvious manner either, you could design the second &quot;adversarial&quot; machine learning model to only generate adversarial images which appear benign to a human operator. It is also possible to programmatically deduce information about machine learning models, such as information about their training data-sets or the computational resources that went into building it, which could provide damaging information to our nation&#39;s enemies. <br/><br/>Overall these systems raise both moral and practical issues and should not be relied upon for policing or domestic security in general. They are too easily countered, introduce an additional attack vector to bad agents by which citizens&#39; information can be stolen or leaked, and produce disparate impacts against vulnerable populations. This is not a road which the government has any business following, let alone trailblazing. ",
1,DHS-2021-0015-0040,Comment Submitted by David Parks,"In the mid/late 1960&#39;s the National Security Agency had a solid policy for us communications intercept operators to never copy the communications of a US citizen. The moment it was discovered that a intercept operator had began to copy a communication that involved a US citizen we were instructed to end the intercept, and to destroy the record.<br/><br/>When my US Army Security Agency obligation ended in late1969 I took a personal vow to do my best to keep abreast of developments within the National Security Agency. Throughout the following decades I did so, and continue to do so, and when I learned of the passing of The Patriot Act which allowed the NSA to turn inward and spy on US citizens I was greatly alarmed. I knew from my experience working at the NSA that great harm to our citizens privacy would result by allowing this huge intelligence agency to snoop unfettered in America&#39;s electronic communications establishment. And now DHS is surveying see how we citizens feel about also adding omnipresent CCTV cameras with facial recognition to the mix. Communist China has that, a regular citizen there has NO expectation of privacy, can you say &quot;&#39;social credit&#39; system&quot;. Any US citizen knowing the truth about the extent of these internal surveillances and what they evidently lead to would, rightly, reject the further encroachment upon our individual right to privacy. I do. I also believe that the Patriot Act should be allowed to die, the DHS be disbanded, and the NSA &quot;ear&quot; once again turned outward. I believe these views of mine are very conservative.<br/><br/>And a complete fantasy of mine, why; because our US government, through their beloved cats paw, the DHS has already decided to gift us with this Orwellian future. I quote you;<br/><br/>&quot;...and then designing and deploying them in a manner responsive to the public&#39;s concerns, is critical in gaining public support for DHS&#39;s use of these technologies.&quot; <br/><br/>Such doublespeak - right up there with &quot;The Patriot Act.&quot;",
1,DHS-2021-0015-0042,Comment Submitted by Anonymous,"I believe that any form of facial recognition, and AI technology associated with it, is a threat to the privacy of every individual, and should not be implemented under any circumstances. It is unethical and a violation of the privacy and security of every citizen of the United States. Any form of benefits that this technology could possibly bring is immediately made invalid due to its inherit nature. Facial recognition, and any AI technology associated with it, sacrifices the personal liberties of the United States citizen for the promise of making the nation safer. This promise, whether how true or not it may be, will never be enough to justify the exchange and sacrifice of personal liberties. Facial recognition, and any AI technology associated with it, needs to be banned nationwide. The implementation of this technology is unacceptable.",
1,DHS-2021-0015-0076,Comment Submitted by Anonymous,I am against the use of facial recognition and artificial intelligence to identify individuals.,
1,DHS-2021-0015-0089,Comment Submitted by Anonymous,"As stated, there are serious concerns with privacy and bias in computer-based technology.<br/>Without wasting too much time on details, reasonable examples include:<br/>https://www.rpc.senate.gov/policy-papers/facial-recognition-potential-and-risk<br/>bias: https://www.nytimes.com/2020/12/29/technology/facial-recognition-misidentify-jail.html<br/>https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212<br/>privacy (not facial recognition, but still towards the goal of training AI):<br/>https://www.theguardian.com/technology/2019/oct/09/alexa-are-you-invading-my-privacy-the-dark-side-of-our-voice-assistants<br/>and of course facial recognition can be immediately and easily abused, especially in our extremely legislation-happy country:<br/>https://www.scmp.com/tech/china-tech/article/2138960/jaywalkers-under-surveillance-shenzhen-soon-be-punished-text<br/>I&#39;m assuming that, as a country, we don&#39;t have a strong desire to be like China (70% of us at least).<br/><br/>Perhaps more to the point, other more regressive countries have already tried to fight crime through facial recognition, turns out its pretty ineffective:<br/>https://www.independent.co.uk/news/uk/crime/facial-recognition-police-uk-london-trials-stratford-no-arrests-privacy-human-rights-false-positives-a8429466.html<br/>And a year later, still ineffective: https://www.independent.co.uk/news/uk/home-news/facial-recognition-london-inaccurate-met-police-trials-a8898946.html<br/>In the US, its been very effective at combatting the theft of boots and $12 fuel tanks, but there is suspiciously limited coverage on major crimes: https://www.cnet.com/tech/services-and-software/facial-recognition-overkill-how-deputies-solved-a-12-shoplifting-case/<br/>And of course, in China its use to suppress any behavior deemed wrong, like wearing pajamas in public: https://www.cnet.com/news/chinese-city-uses-surveillance-tech-to-shame-citizens-for-wearing-pajamas-outside/<br/><br/>However, I think it&#39;s safe to say that everyone reading this message is aware of the above and has already formed an opinion on if its &quot;worth&quot; the cost. When a far-too-high percentage of the senate thinks &quot;1984&quot; was an owner&#39;s manual and that its a good idea to outlaw encryption and with it all privacy, it&#39;s difficult to imagine a lot of support for privacy within government. Whats more, there are probably some people who genuinely believe that the Chinese approach is right -- after all, jaywalking is a crime, why not punish it? If children cross the border with their parents, why not separate them and put the kids in cages? After all, entering the country is a crime!<br/><br/>One answer is that our country loves making people into criminals. You are a criminal. Every single other person reading this is a criminal. I am a criminal. I would venture to say that almost every single living breathing human being over the age of 18 in this country is a criminal. LGBTQ individuals are criminals. Homeless people are criminals. In the northeast, its broadly illegal to park your car on the street during the months from November to April, and yet if I go look outside right now, I see criminal after criminal after criminal after criminal.<br/>(Better writers than me on the subject can be found, for example, here https://thehill.com/opinion/criminal-justice/473659-america-has-too-many-criminal-laws and here https://www.heritage.org/crime-and-justice/commentary/too-many-laws-turn-innocents-criminals)<br/><br/>If everyone is a criminal, facial recognition is not only not needed, but opens yet another avenue for abuse through selective enforcement of laws.<br/><br/>Facial recognition and related AI tools appear to be ineffective, biased, invasive, and provides an obvious avenue for abuse all the way from high-level officials to the Barney Fifes of the world.",
1,DHS-2021-0015-0093,Comment Submitted by Anonymous,"I do not believe the government will ever have a right to track me or my American peers with facial recognition or AI-backed softwares. The fallacious nature of restricting freedoms to &ldquo;crack down on crime&rdquo; is not an ideal that this nation was founded upon. Before we hand the volatile, divisive police forces of America even more means to intrude upon American lives, we first need to address the initial training and continuing education our law enforcement communities are subject to. In their present forms, America&rsquo;s police and federal law enforcement divisions are too irresponsible to be trusted with such a potent  piece of technology that is still in its infancy. I also don&rsquo;t trust the government to protect the information they collect using these softwares. It is my belief that the US Government as a whole has absolutely no idea what the internet truly is. As an American citizen, I can confidently state that facial recognition software is a slippery slope down into a much more sinister United States. A United States that is just a shadow of the nation our founding fathers laid down their lives for. It is my right to be a private citizen and I will not allow the government to infringe upon that right. But I don&rsquo;t expect you to listen to this feedback. Your collective hive-mind is made up and listening to the public is not something our 20th-21st century government is known for outside of political campaigns and the quest for power. ",
1,DHS-2021-0015-0099,Comment Submitted by Kevin K,I believe there is a fundamental issue with facial recognition first it takes the owners of law enforcement to prove who was there and there have beenultiple cases where facial recognition has been used to target Americans of darker skin tones due to deficiencies in ai programing as well as false positives. In that framing it is the duty of police to do actual police work since the passing of the patriot act Americans privacy rights have been eroded further and further with no proof of it being used to crack down on foreign or domestic crimes in fact due to the Snowden whistle blower report agency&#39;s in question already proved to be trampling on the rights afforded by our Constitution.,
1,DHS-2021-0015-0036,Comment Submitted by Anonymous,"No, absolutely not, the government has enough databases of personal information that are already unprotected, they don&#39;t need more.",
1,DHS-2021-0015-0054,Comment Submitted by Michael Bothwell,"This technology stifles free speech and violates our constitutional rights. I think the US government should not create, use, affiliate with, or condone the use of facial recognition technology. Not only does the software often have encoded biases which the crew there&rsquo;s try to hide by making the software a black box, The software by design violates fundamental American freedoms. I have the right to freedom of speech and freedom from unlawful search and seizure. By using this technology, the US government is able to search and compile data about citizens without any type of approval from the judiciary. That is plainly unconstitutional. I cannot abide by the affront to our freedoms. ",
1,DHS-2021-0015-0037,Comment Submitted by TERESA MYSYK,This technology has too many bugs and has all the prejudices of the programmers and/or data sets used for learning built in. We all ready know darker skin tones are a problem for current AIs. Tell me about transparency and ways to challenge an identification. This is a privacy nightmare.<br/>Where is the accountability for making a bad/wrong identification? We are still lacking so much of this in our current legal processes.  <br/>How will this information be protected? <br/>How will access to the information be logged? <br/>Where will this information be stored? <br/>For how long? <br/>How is the information destroyed when no longer in use? <br/>Can I opt out? How?<br/>What about Europeans and folks with strong privacy laws in other countries? ,
1,DHS-2021-0015-0055,Comment Submitted by Michael Keefe,"Properly utilized, AI can allow a great reduction in manpower and increase in the amount of work completed for the same effort. The danger with much AI and automation, however is not in the processing of data, but it&#39;s collection, storage, and use. The vast majority of collected data should be deleted immediately. Any data identified for storage including images and the resulting inferred data collected as a result of that need clear storage and usage definitions that can be audited by the public. There have been many security breaches due to poor security standards that place the public at risk from the misuse of this data by government and 3rd parties. Until collection, storage, and auditing methods have been identified, the use of AI and automated data collection systems cannot be implemented.",
1,DHS-2021-0015-0085,Comment Submitted by Anonymous,I disagree.,
1,DHS-2021-0015-0096,Comment Submitted by Anonymous,"Widely circulated facial recognition tech is one of the scariest threats to private citizens in the United States. Modern marketing already seeks to find the best way to profit from every search, transaction, and location you visit.  <br/>In China they have massive centralized databases with gait recognition, facial tracking, and social credit scores. I fear that this kind of persistent tracking is already a blatant reality at in the private sector and an open secret in the public sector. While surveillance capitalism may be impossible to conceal because of how integrated it is into our reality, widespread government surveillance is an opaque black box. It is likely these operations are going on even now and we will find out about them in 5-10 years as we did with PRISM in 2013.<br/><br/>Surveillance weighs on people&#39;s minds; I even feel self-conscious at grocery stores with glib &quot;Smile! You&#39;re on camera!&quot; signs. I think regardless of the pandemic, I will continue to wear a mask, simply for my own peace of mind regarding this issue. I confess to being a somewhat paranoid individual; having data related to my everyday movements constantly logged and analyzed by Artificial Intelligence will not ease this state of being.",
1,DHS-2021-0015-0027,Comment Submitted by Just Nix,Ban all facial recognition.  ,
1,DHS-2021-0015-0029,Comment Submitted by Anonymous,Opposed. Facial recognition and AI should NOT be used. ,
1,DHS-2021-0015-0105,Comment Submitted by Jacob Schapero,"Any deployment of AI technologies should centrally consider the academic and regulatory body of ethical AI use literature, as recently centralized in proposed EU regulation. <br/><br/>Given the potential of AI technologies to run rampant when not held accountable by a human actor (at the very least), governmental approaches should at a minimum seek to ensure that autonomous systems are not allowed to make decisions fully on their own. Focus should remain on curating a regime wherein systems are able to advise and curate information for human actors, but human actors are ultimately still the ones making decisions at a bare minimum.<br/><br/>An even higher standard of scrutiny should be used for any autonomous systems capable of having a legal impact on citizens. AI when deployed for investigatory, administrative, and regulatory functions should have to meet a high standard of scrutiny to ensure the risk of bias or unwarranted infringement of fundamental rights is substantially mitigated. Internal procedures for ensuring oversight and continuous operational audit should be clearly denotated. <br/><br/>",
1,DHS-2021-0015-0104,Comment Submitted by Jack Brown,This is a terrible idea and a dystopian nightmare waiting wanted to happen. How will people feel safe with someone looking over them all the time. AI and Facial Recognition is just another way of United States&#39; government oppression over their citizens which started with NSA spying. I think you should be asking yourself: am I going too for with this? and how can I made Americans feel safer instead of making them feeling like possible terror suspects?,
1,DHS-2021-0015-0184,Comment Submitted by Anonymous,"No, we do NOT want facial recognition (obviously... - who would??). Do NOT implement this.",
1,DHS-2021-0015-0183,Comment Submitted by Hayden Vasquez,"I am absolutely mortified by the lackluster push to get actual public consensus on this because if there was any capacity of effort you&rsquo;d have a lot more negative responses than you&rsquo;ve gotten. Facial recognition software is a nightmare for privacy that inherently violates the constitutional rights on the population it&rsquo;s supposed to allegedly &ldquo;protect&rdquo;. if crime was approached legitimately in other capacities with an actual intent to solve root problems, there wouldn&rsquo;t even be a conversation on facial recognition AI.",
1,DHS-2021-0015-0179,Comment Submitted by B. C.,"dhs doesn&#39;t care about human rights in the first place, so why are you asking me? do you actually care about your citizens opinions or do you just want to know how to sweet-talk the public so people stop complaining?",
1,DHS-2021-0015-0174,Comment Submitted by Edward Wisneski,"Facial recognition technology, and to a lesser extent artificial intelligence technology, should not be developed under the control of this or any government. The uses that these technologies could be put to, uses directly against the people, are too dangerous to chance. Elected leaders and government bureaucracies cannot be trusted to act in the people&#39;s best interest. We have seen what the People&#39;s Republic of China can do to its own people. We have seen what the Federal Government has done under the guise of the PATRIOT Act. These technologies should be left to the private sector and regulated by the Federal Government. ",
1,DHS-2021-0015-0176,Comment Submitted by Frederick Ahrens,I am personally against facial recognition technology. I would like it to not continue anymore than it has to.,
1,DHS-2021-0015-0186,Comment Submitted by Anonymous,"Facial recognition should absolutely not be used by DHS at all, and machine learning (&quot;AI&quot;) should be used very carefully for the following reasons: <br/><br/>- Facial recognition in its current form does not reliably recognize people of color, often getting individuals confused. This not only makes it useless for tracking persons of interests, but may lead to innocent citizens getting into legal trouble. <br/><br/>- Machine Learning amplifies biases that exist in society at large, and should therefore not be used in any law enforcement context if we&#39;re concerned about actual safety, justice, and fairness.<br/><br/>- The damage that hackers or foreign adversaries could do with information that includes facial recognition data it is so great that the benefits  are NOT worth the risk of collecting that information in the first place. <br/><br/>- Mass surveillance of american citizens compromises the ideals this country stands for, that homeland security should be seeking to protect. It also undermines trust and confidence from the public that is crucial for investigations to succeed. ",
1,DHS-2021-0015-0192,Comment Submitted by Eric Yale,"Facial recognition of the general public is one step closer to a Totalitarian Government as it serves only to categorize American Citizen&#39;s into groups that provide Government Officials the ability to identify those citizen&#39;s who agree or disagree with their form of Governmental control.<br/><br/>Like ALL forms of Government oversight, this to will be abused irrespective of the guidelines or Laws for its use.  There is currently NO oversight feature used by the Government that has not been abused and will continue to be abused by those who seek total power and control over the citizenry.  <br/><br/>Given those who today and over the past decades have NOT been held accountable for unlawful acts against American citizens, I am OPPOSED to allowing the use of Facial recongnition programs for the general public. ",
1,DHS-2021-0015-0194,Comment Submitted by Anonymous,"Using facial recognition technology on a person should follow the same requirements as demanding ID from a person on the street - the person must already be suspected of a crime before the request is made. In other words, to protect people&#39;s rights, facial recognition technology must only be used with probable cause. Facial recognition should never be used in public places, but it can be a useful tool for identifying a specific suspect who has been caught on tape committing a crime.<br/><br/>Blanket use of facial recognition in public places opens people of various political or social groups to potential abuse by the government. Even if agencies don&#39;t actually abuse the data, many people will expect them to. Even if this made the streets safer, it wouldn&#39;t be worth it.",
1,DHS-2021-0015-0214,Comment Submitted by Anonymous,"I feel as though this is a major gateway to destruction of privacy, similar to the PATRIOT Act. AI is pretty shoddy, as you&#39;ve no doubt seen the pixel autocompletes that are trained on white men only. Why should we waive our privacy rights away to stop a few terrorists? ",
1,DHS-2021-0015-0207,Comment Submitted by Anonymous,"I believe online data is already far too accessible without a warrant. I would absolutely not support the expansion of the amount of information collected on Americans, or the expansion of the types of information collected, in any way. Without increasing the amount of data collected on Americans, most facial recognition systems would be crippled with inaccuracy and bias, as they are currently. As such, I do not support the expansion of AI or facial recognition technologies due to their bias, impact in encouraging increased data collection, unreliability, and also because most AI&#39;s and Facial Recognition systems are &#39;black boxes&#39; -- Meaning, once trained, they do not provide details on how they come to their conclusions. This is an especially unacceptable flaw for any system the government is employing on a widespread scale.<br/><br/>In order for such systems to be maintained and developed, large stores of personal information would have to be kept in centralized repositories. This is unacceptable from a data security standpoint, even if extreme precaution was taken to safeguard the repository, and even if it was seemingly mundane information such as names matched to faces. <br/><br/>Finally, developing such a system would make it liable to be expanded and abused in many ways, which is unacceptable due to the possible consequences to the security, privacy, and freedom of choice of Americans. I would support absolutely no expansion of AI or facial recognition systems, and would advocate that already developed systems be destroyed. <br/><br/>It&#39;s a slippery slope to dystopia. Either the system proves useless and little is gained, or the system proves effective, and there becomes a central repository containing leverage on every single American, which is absolutely unacceptable to be held by anyone, let alone a government entity. It goes without saying that expansion of these systems harms Americans&#39; privacy, security within their own country, due process, and freedom to live each day without fear. Truly I&#39;m perplexed that comments would be requested. ",
1,DHS-2021-0015-0209,Comment Submitted by Anonymous,"This is totally government over-reaching Department of Homeland Security need to be held accountable to getting warrants just like everyone else. Facial recognition is a digital stop and frisk. Theres lots of evidence that facial recognition makes lots of mistakes and misidentifies people, especially people that are black and brown. Even considering Facial Recognition before the black/brown identification problem is addressed furthers institutionalized racism and places an unfair additional burden on black/brown people proving their innocence after being misidentified by AI systems. <br/><br/>https://www.aclu.org/news/privacy-technology/wrongfully-arrested-because-face-recognition-cant-tell-black-people-apart/<br/>https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/<br/>https://gal-dem.com/facial-recognition-racism-uk-inaccurate-met-police/  ",
1,DHS-2021-0015-0201,Comment Submitted by Anonymous,"In other words, the three-letter agencies are discussing on how to brainwash us into giving up our right to privacy.",
1,DHS-2021-0015-0205,Comment Submitted by Anonymous,"Facial recognition, especially with AI assistance, is fundamentally a violation of peoples&#39; privacy.  Also, with how poorly certain federal agencies have admitted to tracking crime, there is no reason to implement this.",
1,DHS-2021-0015-0208,Comment Submitted by Anonymous,"This is unethical, may lead to abuse, and violates privacy.",
1,DHS-2021-0015-0211,Comment Submitted by Trevor Toros,"It is my sincere belief that utilizing any automated and continuous recognition technologies on the American public is akin to random stop &amp; frisk searches by the government. While there is generally no expectation of privacy in public spaces, the continuous search and seizure of personal information and data (faces, movements, locations, activities, etc.) is concerning - especially without a warrant for those personal information. <br/><br/>Automated gathering of this type of data could easily lead to adverse results in law enforcement or governance. The adoption of these sorts of policies and explorations into AI and facial-recognition technologies would constitute further encroachments onto the privacy of all Americans.",
1,DHS-2021-0015-0195,Comment Submitted by The Policing Project at NYU Law,"Comment re: Public Perceptions of Emerging Technologies
The Policing Project at NYU Law School submits this brief comment in response to the proposed 
Information Collection Request filed by the Science and Technology Directorate of the Department of 
Homeland Security (DHS).1 We understand DHS to be taking public comment on whether collecting 
information on public perceptions of its use of AI/ML technologies, in particular facial recognition 
technology (FRT), is necessary. For the reasons explained below, we believe that not only is this 
information collection necessary – it is essential.
Currently, we are aware of four reported purposes for which DHS uses FRT: digital access, 
domestic law enforcement, border and transportation security, and national security and defense.2 Because 
our expertise lies primarily in matters of domestic law enforcement, our comment is especially focused on 
DHS’ use of FRT for this purpose, but the principles and concerns expressed below also apply to other 
DHS use cases that present risks to the public’s civil rights and liberties.
The Policing Project is a research center at NYU Law School and our mission is to partner with 
communities and law enforcement to promote public safety through transparency, equity, and democratic 
engagement.3 We conduct research, but also do work on the ground all over the country, both with policing 
agencies and the communities they serve, to promote democratically-accountable approaches to public 
safety. Ours is an all-stakeholders approach. Everywhere we work, we endeavor to do so both with 
communities affected by law enforcement, and with law enforcement themselves. By listening to, and 
working with, everyone we hope to move the needle toward greater public safety that is just, nondiscriminatory, and effective. 
Often when people talk about a lack of accountability in policing, they mean that when an officer 
harms someone, or surveillance techniques are deployed inappropriately, no one is held responsible—
officers rarely are disciplined or prosecuted, courts admit evidence the police have seized illegally, and civil 
lawsuits are not successful. 
This is back-end accountability—it kicks in only after something has gone wrong, or is perceived 
to have gone wrong. Back-end accountability is very important, but because it can only target misconduct, 
there is a limit to what it can accomplish to guide policing before it goes awry.
At the Policing Project, our work is focused on ensuring accountability and democratic 
participation on the front end. Democratic or front-end accountability means the public has a voice in 
setting transparent, ethical and effective policies and practices before the government can act. 
In a democratic society, the adoption and use of technologies that are capable of collecting 
information about and surveilling the public by agencies charged with keeping the public safe must be guided by democratic legitimacy. In other words, the public must have an empowered voice in decisions 
around acquisition and use of these technologies. This is particularly so for communities of color, especially 
Black communities, who too frequently have been on the receiving end of state-sponsored surveillance.
In our view, the lack of democratic front-end accountability explains many of the problems with 
law enforcement today. Take facial recognition as an example. Law enforcement agencies have acquired 
and used this technology in secretive ways, without adequate guardrails around use cases or means of use. 
People are distrustful when surveillance technologies are used without transparency and rules. Worse, 
without democratically authorized safeguards in place, harm inevitably ensues. And nowhere is mistrust 
and potential for harm greater than in Black and brown and other marginalized communities, like immigrant 
communities, which already feel the brunt of many discriminatory policing practices. If there is going to be 
public trust and democratic legitimacy around surveillance technologies—especially in the communities 
understandably most distrustful of policing at present, there must be complete transparency and a regulatory 
approach that recognizes and addresses harms.
The problem we face is that today in too many jurisdictions—including the federal government—
the use of FRT is entirely unregulated. This is untenable. The technology simply should not be in use until 
a regulatory framework is in place.
And that is why we support this information collection. Engaging the public around government 
use of these technologies is a first and necessary step toward building a workable regulatory framework. 
DHS states that its mission is to “safeguard the American people.”4
In light of the serious harms raised by 
law enforcement use of AI/ML technologies like FRT, it is essential that the public have a meaningful voice 
in the debate around whether and how DHS uses these technologies to keep us safe. In particular, we urge 
DHS to ensure that its work to collect public perceptions of these tools makes special efforts to engage 
those communities most impacted by their use, such as communities of color and immigrant communities",
1,DHS-2021-0015-0223,Comment Submitted by Clearview AI,"RE: Public Perceptions of Emerging Technology
Clearview AI, a U.S. based company dedicated to providing the most cutting-edge 
technology to law enforcement to investigate crimes, enhance public safety and 
provide justice to victims, is pleased to provide public comment addressing the issue 
of artificial intelligence (“AI”), including facial recognition. 
Facial recognition technology is a critical tool to ensure public safety, provided that 
proper safeguards are established. Reasonable and effective policies eliminate many 
of the concerns surrounding the technology, including, but not limited to, discrimination 
and privacy concerns. 
Such protections include: 
(1) Accuracy requirements and non-discrimination; 
(2) Records to enable an audit or review of each use;
(3) Match verification and secondary review of result; 
(4) Privacy protections by excluding and/or redacting explicit images;
(5) Authorization and accountability by implementing a use policy;
(6) Independent verification, the match cannot be used as sole source for positive 
identification;
(7) Prohibition on use by agency for persons engaged in protected activities. 
 
HIGH-PERFORMING ALGORITHMS (AS DETERMINED BY NIST) DO NOT 
CONTAIN RACIAL BIAS & ARE AT LEAST 99% ACCURATE 
The Director of the Information Technology Laboratory for National Institute of 
Standards and Technology (“NIST”), Dr. Charles Romine testified in 2020 before the 
U.S. Homeland Security Committee that with the highest-performing algorithms they 
saw “undetectable” bias, further noting, that they did not see a “statistical level of 
significance” related to bias in these top-performing algorithms.1 Indeed, NIST’s 
October 2021 evaluation of Clearview’s facial recognition algorithm found 99% 
accuracy for all demographics – highlighting the dependability and accuracy in 
advanced algorithms.
As noted by the U.S. Government Accountability Office (“GAO”) [r]ecent 
advancements in facial recognition technology have increased its accuracy and its 
usage.” In fact, unlike older algorithms which use manual measurements, advanced
and high-performing algorithms use a form of artificial intelligence called a “neural 
network”. These artificial neural networks operate similar to a biological brain, 
transmitting various signals to other neurons to map out the image. For example, 
Clearview’s high-performing algorithm’s neural networks are trained on millions of 
examples of diverse faces from all ethnicities to ensure there is no racial bias in its 
algorithm. 
A larger database of images further promotes accuracy and eliminates the possibility 
of racial bias because it is more reflective of a diverse population. It also reduces the 
likelihood of law enforcement making false positives. A database of 1 billion images 
that are routinely updated provides a diverse data set that matches diverse 
populations. Further, retrieval rank is a setting whereby an algorithm can be modified 
to return more results that may not be as accurate. Setting a low retrieval rank will 
always return more false positives. High-performing algorithms should be hardcoded 
to not allow the user to modify the retrieval rank, thereby limiting the return of false 
positives. The facial recognition algorithm produces a set of potential matches that are 
then reviewed by human investigators and trained analysts who serve as peers in the 
review process.
Finally, beyond improving an otherwise manual process, facial recognition contributes 
to more accurate identification. The National Institute of Science and Technology has 
found that forensic examiners performed best when supported by facial recognition technology and the most accurate performance resulted when these efforts are 
combined. “[A] team of scientists from . . . NIST and three universities has tested the 
accuracy of professional face identifiers, providing at least one revelation that 
surprised even the researchers: Trained human beings perform best with a computer 
as a partner, not another person.”5
THE DATASET IS CRITICAL TO HELP SOLVE CRIMES AND RESCUE VICTIMS 
Any policy that encourages restricting the data set to a facial search against 
Department of Motor Vehicles (“DMV”) records or criminal databases (such as 
mugshots) is extraordinarily limiting. This will not facilitate the identification of an 
adolescent victim or a suspect committing crimes within the state that do not exist in 
these limited data sets. 
In actuality, limiting a law enforcement agency to look for perpetrators in criminal data 
sets such as mug shots could encourage the resolution of crimes that point to repeat 
offenders and discourage the resolution of investigations involving unknown persons 
that are not in the typical local data set. 
For geographic areas that are highly intertwined, such as New England, where crimes 
can easily be perpetrated in multiple states, using a DMV dataset causes many 
challenges for law enforcement. Specifically, in July 2021, a group of 11 heavily armed 
men with the Rise of the Moors group was stopped by State Police on I-95 in 
Wakefield, Massachusetts at 1:30 a.m. while traveling from Rhode Island to Maine for 
“training.” The standoff lasted 9 hours with a shelter-in-place order issued for the 
surrounding area.6 The men refused to provide identification and officers were unable 
to use facial recognition technology, which resulted in a delay in the booking process 
and investigation. And even if they could use the technology and if it were limited to 
Massachusetts DMV images, there likely would not be matches unless they were 
Massachusetts residents. Additionally, open-source data has been a game changer for rescuing and identifying 
victims such as children. Law enforcement has significantly increased the rate of 
identifying child victims of sexual abuse online using high performing facial recognition 
technology. 
FACIAL RECOGNITION TECHNOLOGY SHOULD USE PUBLIC INFORMATION, 
WITH LIMITED EXCEPTIONS – ELIMINATING PRIVACY CONCERNS 
Facial recognition technology service providers should only use lawfully sourced 
images including those from the public internet, government databases, or client 
enrollment services. For example: 
? Open Social Media Posts and other online profiles (photos from a publicly
available Instagram page (not a private post));
? News articles (photos taken as a part of a news story);
? Personal and professional websites (professional photo from work biography);
? Mug shots and other criminal databases;
? Public records sites and thousands of other open sources.
The U.S. Supreme Court has made it clear – “creation and dissemination of 
information are speech within the meaning of the First Amendment.”7 Algorithms that 
collect public information and then compare photographs provided by law enforcement 
is exactly the type of information dissemination intended by the Supreme Court. By 
limiting the data to only public information, many of the privacy concerns are alleviated. 
NOT ALL FACIAL RECOGNITION TECHNOLOGY ALGORITHMS ARE USED AS 
SURVEILLANCE – SOME ONLY USE IT AFTER AN EVENT HAS OCCURRED 
Software that provides facial recognition technology is not inherently surveillance. 
While some countries and certain algorithms can, and do, use the technology as 
surveillance, Clearview AI, for example, does not.8 Without the surveillance function, 
the technology is used after an incident necessitates the identification of a person. 
Surveillance is the live monitoring of behavior, activities, or information. Using an 
investigative tool, including LexisNexis, a DMV database, Google, or any other search 
engine to look for information after a crime or incident occurs, is not surveillance. Facial recognition technology is used to generate leads connected to an incident after 
an event has occurred. The process of uploading an image of a suspect, victim, or 
person of interest after an incident occurs is not “monitoring” or “surveillance” of an 
individual. Rather, it is an information gathering step in the investigative process 
equivalent to having an eyewitness review images to determine if they recognize a 
face (although the AI will be more accurate than the eyewitness). Facial recognition, 
allows this process to be advanced and accurate, thus delivering more timely and 
reliable leads.
Example: Jan. 2021 Capitol Insurrection 
Facial recognition technology was not used as surveillance during the incidents 
occurring on January 6, 2021, at the United States Capitol. It was used after the fact 
to investigate criminal conduct. Law enforcement entities sought facial recognition 
technology to determine if their sometimes partial or fleeting photos of those involved 
in criminal conduct could be matched with publicly posted photos on the internet.9
RESPONSIBLE USE OF FACIAL RECOGNITION TECHNOLOGY IS SUPPORTED 
BY THE PUBLIC & PROVIDES SIGNIFICANT BENEFITS TO THE PUBLIC SAFETY
According to November 2021 research performed by Zogby Analytics, 75% of 
Massachusetts residents and more than 75% of Virginia residents see the use of facial 
recognition technology by law enforcement as appropriate and beneficial.10 
Specifically: 
? 87% of Massachusetts residents said law enforcement should be able to search 
publicly available social media photos to help find missing children and to find 
or prosecute child sex offenders/traffickers;
? 83% of Massachusetts residents said law enforcement should be able to search 
publicly available photos to help find endangered adults and 82% are in favor 
of using the technology to positively identify endangered individuals;69% of Massachusetts residents think that private facial recognition database 
that only includes arrest mug shots would have a risk of being discriminatory 
with 52% saying it was a high or moderate risk; 
? 90% of Virginia residents said law enforcement should be able to search 
publicly available social media photos to help find missing children and to find 
or prosecute child sex offenders/traffickers; 
? 84% of Virginia residents said law enforcement should be able to search 
publicly available photos to help find endangered adults and 86% are in favor 
of using the technology to positively identify endangered individuals; 
? 70% of Virginia residents think that private facial recognition database that only 
includes arrest mug shots would have a risk of being discriminatory with 52% 
saying it was a high or moderate risk.
These results match with a 2019 study by the Center for Data Innovation, which found 
that only 26 percent of Americans believe the United States government should strictly 
limit the use of facial recognition technology, and only 18 percent believe the 
government should strictly limit its use if it comes at the expense of public safety.11 A 
2020 study by NetChoice similarly found that 83 percent of Americans want state and 
local governments to improve law enforcement use of facial recognition rather than 
banning it.12 A majority of individuals polled by NetChoice supported the technology’s 
use for lead generation, keeping child predators off school grounds, finding missing 
senior citizens, and locating terrorists during an active terrorist attack.
Trafficking and Crimes Against Children 
Facial recognition offers unprecedented capabilities to identify stalkers, rapists, child 
abusers, and other online predators and could facilitate identification of previously 
unknown child victims depicted in child sexual-abuse material proliferating online. 
A Nevada Police Department investigator needed to identify a child that was being 
sexually exploited before she left the city. While online prostitution ads do not always 
provide identifying information for the workers, the ads often have high quality pictures 
that are suitable for facial recognition searches. The investigator submitted one of the images from the ads, and within 10 to 15 
seconds facial recognition technology provided a possible lead, including a link to the 
girl’s Instagram page. By researching the contents of the public Instagram profile, the 
investigator positively identified the victim within two hours of the search – and 
confirmed that she was a 16-year-old juvenile. After booking an “appointment” for the 
next day, the investigator recovered the victim and apprehended her trafficker. She 
had been trafficked and abused since she was 13 years old. Time was of the essence 
and local law enforcement access to the technology was critical to this victim’s safety.
Attempted Child Abduction 
A suspicious YouTube video was shared to a Michigan police department Facebook 
account. The video showed conversations in which an adult male subject attempted 
to solicit child sexually abusive material from a 14-year-old female, and then attempted 
to abduct the juvenile victim at a park. A vehicle and partial license plate was visible 
in the video. A facial recognition search of the profile photo resulted in a match to the 
suspect’s real social media account. Further investigation uncovered the suspect had 
a vehicle matching the partial plate and vehicle seen in the video. The investigative 
lead was forwarded to local authorities who continued the investigation and 
apprehended the suspect.
Identifying a Killer Who Targeted LGBTQ Victims13
Three members of the LGBTQ+ community were shot and killed by a man at a local 
home in Detroit, Michigan, in 2019. The Detroit Police Department used facial 
recognition – in combination with other investigative tools – to help identify the suspect 
based on video images from a nearby gas station. The suspect was charged with three 
counts of murder, in addition to other charges.
Identifying a Serial Armed Robber14
In 2018, detectives in Munster, Indiana, tried to identify a suspect who had attempted 
to rob a local business at gunpoint, after releasing a photo from the location’s 
surveillance system which was shared by local media. No leads were generated until 
they used facial recognition and found possible match, a man that had skipped parole 
after serving a prison sentence for nine armed robberies in Illinois. The suspect was 
identified after the store owner was shown a photo lineup that included the man’s picture and was arrested several months later. Without facial recognition, the suspect 
would likely never have been found.
Scam Artist 
Detectives in North Carolina were working to identify a scam artist in a fraud case. The 
detective searched a photo of the fraud suspect using facial recognition technology 
and was able to identify him from an article in New Jersey. The suspect was wanted 
in New Jersey for similar crimes.
SAFEGUARDS TO ENSURE THE RESPONSIBLE USE OF FACIAL RECOGNITION 
TECHNOLOGY 
Facial Recognition Technology Civil Liberty Protection Principles
1. Accuracy and Non-Discrimination. Facial recognition technology must meet 
a minimum accuracy standard for face matches in all demographic groups to 
ensure non-discrimination against any demographic group. A facial recognition 
service shall be deemed to meet the standards by having participated in the 
business-relevant tracks evaluated by the Face Recognition Vendor Test 
(FRVT) from NIST and scored well. The algorithm is recommended to have 
received 99% or better true positive rates across all demographic groups at 
stringent false positive rates as selected by FRVT, or at high retrieval ranks. 
We note that FRVT regularly puts out new test datasets and retires old ones, 
so our recommendations must be put into context. On an absolute scale, 
algorithms will only get more accurate. Notwithstanding the foregoing, a lower 
standard of accuracy shall be acceptable to identify a person under the age of 
18 in connection with providing the facial recognition service for protecting a 
minor at risk of abuse, kidnapping, or other threats to a minor’s life or safety.
2. Privacy. The facial recognition technology must be designed so that it protects 
the privacy of persons by excluding, redacting, blurring, or otherwise obscuring 
nudity or sexual conduct, involving any identifiable person. This limitation shall 
not apply to images made available to the facial recognition service provider 
by an authorized law enforcement agency seeking to protect a minor at risk of 
abuse, kidnapping, or other threats to a minor’s life or safety.
3. Records. Any facial recognition service provider must ensure there is a 
mechanism to produce a record that can be used to audit or review the 
information used to make a match of a person. Match Verification. All facial recognition technology search results must be 
subjected to a secondary review and verification prior to acting on the match 
of a person.
5. Authorization and Accountability. A facial recognition technology use policy 
must be in place prior to utilizing the technology.
6. Independent Verification of the Lead. Information provided by facial 
recognition technology may be used as lead information to assist in identifying 
a person for an investigative purpose. A match provided by facial recognition 
technology cannot be used as the sole source for positive identification of a 
person.
7. Prohibition on Use by Law Enforcement for Persons Engaged in 
Protected Activities. Facial recognition technology may not be used to 
identify a person participating in constitutionally protected activities in public 
spaces unless there is an articulable investigative purpose.
Requirements for Facial Recognition Services Provider
1. Undertake reasonable steps to ensure that its facial recognition technology 
meets the standards of each of the Facial Recognition Safety Principles before 
it may provide facial recognition technology to any agency.
2. Require each user of its facial recognition technology to agree to abide by Facial 
Recognition Safety Principles in any use of its technology as a precondition to 
it providing such technology to the user.
3. Put into place a system of data security controls on any images or biometric 
information provided to the facial recognition service by any user to protect the 
security of such images or data, including steps to protect facial recognition 
technology data transmission, storage, and processing to ensure the privacy 
and security of such images or data, using commercially reasonable encryption 
and other cybersecurity and privacy best practices.
4. Notifying to the agency of any security breach or compromise of any data 
provided to the facial recognition service, as applicable, in the law of the 
jurisdiction.
5. Providing user training on the use of the facial recognition technology.",
1,DHS-2021-0015-0216,Comment Submitted by Matthew  Feeney,"To Whom It May Concern:

I appreciate the opportunity to submit to the Department of Homeland Security’s call for comments on the agency’s use of Artificial Intelligence (AI). 

The Cato Institute is a public policy research organization dedicated to the principles of individual liberty, limited government, free markets, and peace. The Cato Institute’s Project on Emerging Technologies, of which I am director, is dedicated to developing a unique and optimistic vision of emerging technology consistent with these principles. 
Summary

As with other new and emerging technologies AI - the exhibition of traits associated with human intelligence by machines - provides a range of risks and opportunities. AI tools have been used to improve healthcare, gaming, marketing, agriculture, and many other industries. Yet AI can also be used to conduct mass surveillance and worsen preexisting racial biases. These risks and opportunities ought to prompt lawmakers, regulators, and agency officials to approach AI with caution and transparency but also with optimism. With the correct policies in place, AI can aid the Department of Homeland Security (DHS) rather than be used to worsen the surveillance of law-abiding Americans and residents. In this comment, I will outline why concerns about AI are justified and what policies could alleviate these concerns. 
AI Concerns
The most prominent and concerning application of AI in law enforcement is the use of facial recognition technology (FRT). DHS plans to expand its use of FRT.  This is particularly worrying given the scale of DHS use of the technology and its track record of using FRT.  
According to an August 2021 Government Accountability Office (GAO) report, DHS has used FRT for investigations, border security, and national security and defense.  The same reported noted that DHS, in addition to having access to passport and visa photos, can query social media photos via Clearview AI, a firm that builds a search engine of people’s faces based on social media photos.  That DHS can access photos associated with millions of law abiding Americans raises legitimate worries about civil liberties concerns. 
DHS surveillance does not affect all travelers or residents equally. AI-fueled surveillance tools such as FRT and predictive policing systems have a track record of discriminating against minority racial groups.  This is obviously of concern to members of those minority groups who travel to the U.S., including American citizens, permanent residents, and family members of American citizens. Surveillance issues aside, travelers who belong to minority groups are more likely to have their travel interrupted by FRT false positives. A Georgetown Law report on the use of FRT found that DHS had prioritized traveler convenience over valid identification verification, with a 96 percent accuracy rate being considered adequate.  But FRT with such an accuracy rate would hardly be efficient at catching imposters, as the Georgetown report stated:

“DHS clearly is focusing on making its face scan system minimally inconvenient for travelers using valid credentials. DHS’ sole accuracy requirement for the system is that 96 percent—or at least 24 out of 25—of travelers flying under their own identity are correctly accepted by the system and allowed to proceed to boarding.48 But due to the trade-off explained above, emphasizing the success of the system at verifying valid credentials—perhaps to minimize unnecessary hassle and delays at already-busy international airports—may increase the risk that impostors go undetected. 
Indeed, analysis of face recognition algorithms indicates that some likely comparable systems would not perform very well at screening the type of impostor the system is likely to encounter: someone who fraudulently uses the boarding documents of a different person of the same age, gender, and country of origin or ethnicity. According to research conducted by the National Institute of Standards and Technology (NIST), face recognition systems, like humans, have a harder time distinguishing among people who look alike.49 The algorithms tested by NIST are more likely to falsely match individuals who are similar in appearance, a fact that NIST notes ‘present[s] a security vulnerability to, for example, a passport gate.’” 
Outside of airports DHS surveillance continues, and in recent years there have been several examples of DHS surveillance targeting Muslims in particular and of DHS officials expressing an interest in expanding such surveillance. During the Trump administration, U.S. Customs and Border Protection acting commissioner Kevin K. McAleenan compiled a report recommending that DHS keep some Muslims under observation for “a long-term basis.”  DHS’ Countering Violent Extremism (CVE) program has been widely criticized for its ineffective and intrusive surveillance of Muslims.  AI experts were particularly critical of DHS’ planned Extreme Vetting program.  Fortunately, Immigration and Customs Enforcement – a DHS agency – dropped its machine learning requirement from the program, which aimed to automatically surveil social media for signs of potential terrorist acts.  Nonetheless, we should be prepared for the next wave of panic prompted by terrorism or extremism. The last few years have provided ample examples of law enforcement agencies being willing to embrace AI surveillance tools. The list of targets of American federal government surveillance is long and diverse, and we should expect for DHS and other federal agencies to feel pressure from the public and lawmakers to us AI-based tools to conduct surveillance and target minority groups.  The policies outlined below would mitigate this risk.
AI Policies

In order to ensure that DHS use of AI promotes transparency and does not erode civil liberties the following policies should be implemented. 

1) Ban on Facial Recognition Real-Time Capability

FRT should be used as an investigative tool and should not be used to analyze live video feeds. DHS has used FRT at select airports across the country and has expressed interest in using small drones with FRT capability for Border Patrol.  

FRT use at airports can reduce the time travelers spend in queues, and it is likely that FRT will increasingly become the norm. Such screening does rely on the analysis of a photo and live images of a traveler’s face. If FRT is to continue to be used in airports it should not be deployed before a policy requiring swift deletion of analyzed images after identity confirmation, regardless of the national origin of the traveler. 

2) Database Requirements
Databases DHS uses for FRT queries should be purged of data unrelated to missing persons or people with outstanding warrants for violent crimes. These databases should be purged of images that are not associated with a missing person or a suspect of a violent crime at least once every thirty days. This database requirement should not preclude the deployment of FRT that has been trained with more inclusive databases.
3) Open-Source Requirement
Members of the public should be able to study AI systems DHS is using to conduct surveillance and predict crime. Such a requirement will increase accountability and provide the public with a means to identify any problems associated with accuracy rates across different racial groups.  
4) Mandatory Public Hearings and Accuracy Testing Before Deployment
DHS should mandate that any new surveillance device be revealed to the public months before deployment. In the case of AI-based surveillance tools such revelations should be accompanied by the results of accuracy testing. ",
