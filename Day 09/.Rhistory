tweets <- readRDS(file = "tweets.rds")
library(lubridate) #for extracting dates
library(tidyverse)
library(quanteda)
library(stm)
library(wordcloud)
View(tweets)
elements <- str_split(tweets$created_at, fixed(" "), n=2)
tweets$Date <- map_chr(elements, 1)
tweets$month <- month(as.POSIXlt(tweets$Date, format="%Y-%m-%d"))
View(tweets)
clean_tweets <- function(x) {
x %>%
# Remove URLs
str_remove_all(" ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)") %>%
# Remove mentions e.g. "@my_account"
str_remove_all("@[[:alnum:]_]{4,}") %>%
# Replace "&" character reference with "and"
str_replace_all("&amp;", "and") %>%
# Remove punctuation, using a standard character class
str_remove_all("[[:punct:]]") %>%
# Remove "RT: " from beginning of retweets
str_remove_all("^RT:? ") %>%
# Replace any newline characters with a space
str_replace_all("\\\n", " ") %>%
# Make everything lowercase
str_to_lower() %>%
# Remove emoji
str_remove_all('[:emoji:]')%>%
# Remove any trailing whitespace around the text
str_trim("both")
}
tweets$text<-tweets$text %>% clean_tweets
tweetCorpus <- corpus(tweets$text)
tweetCorpus <- tweetCorpus %>%
tokens(what = "word") %>%
tokens_remove(c(stopwords("english")))
docvars(tweetCorpus, field = "month") <- tweets$month
docvars(tweetCorpus, field = "university") <- tweets$screen_name # covariance field university
View(tweetCorpus)
View(tweetCorpus)
tweetDfm <- dfm(tweetCorpus)
topfeatures(tweetDfm, n = 100, scheme = "docfreq")
?convert
tweets.stm <- convert(tweetDfm, to = "stm")
View(tweets.stm)
ut <- prepDocuments(tweets.stm$documents,
tweets.stm$vocab,
tweets.stm$meta,
lower.thresh = 10)
out <- prepDocuments(tweets.stm$documents,
tweets.stm$vocab,
tweets.stm$meta,
lower.thresh = 10)
model <- stm(out$documents, out$vocab,
K = 5,
max.em.its = 100, #its number should follow searchK output
data = out$meta,
init.type = "Spectral")
labelTopics(model, c(1:5), frexweight = 0.5,n = 15)
labels <- labelTopics(model, n = 20)
topwords <- data.frame("features" = t(labels$frex))
colnames(topwords) <- paste("Topics", c(1:5))
topwords[1:5]
par(bty="n",col="grey40",lwd=6)
plot(model, type = c("summary"),
labeltype = c("frex"),
topic.names = c("Topic 1: graduation",
"Topic 2: underg recruitment",
"Topic 3: grad recruitment",
"Topic 4: campus events",
"Topic 5: academic prestige"),
main = c("Topic distribution"),xlim = c(0, 0.5),
custom.labels="")
cloud(model, topic = 1, min.freq=3)
plot(model,
type="perspectives",
topics=c(2,3),
plabels = c("underg recruit","grad recruit"))
result1 <- estimateEffect(1:5 ~ university, model,
meta = out$meta, uncertainty = "Global")
topiceffect1<-summary(result1, topics = c(1:5))
topiceffect1
plot(x = result1,
covariate = "university",
topic = c(5),
model = model,
method = "pointestimate",
xlim = c(0.1, 0.5))
result2 <- estimateEffect(1:5 ~ month, model,
meta = out$meta, uncertainty = "Global")
topiceffect2<-summary(result2, topics = c(1:5))
topiceffect2
plot(x = result2,
covariate = "month",
topic = c(2),
model = model,
method = "continuous",
xlim = c(1, 12))
plot(x = result2,
covariate = "month",
topic = c(2),
model = model,
method = "continuous",
xlim = c(0, 12),
ylim = c(0.15, 0.3),
linecol = "skyblue", width = 20, lwd=2)
result3 <- estimateEffect(1:5 ~ month + university + month*university, model,
meta = out$meta, uncertainty = "Global")
topiceffect3<-summary(result3, topics = c(1:5))
topiceffect3
?stm
storage <- searchK(out$documents, out$vocab, K = c(3:10),
data=out$meta)
plot(storage)
install.packages("spacyr
")
library(spacyr)
install.packages("spacyR")
yes
install.packages("spaCyr")
library(spacyr)
library("spacyr")
install.packages("spacyr")
library("spacyr")
spacy_install()
class(docvars(tweetCorpus))
class(docvars(tweetCorpus),= "university")
class(docvars(tweetCorpus), field= "university")
class(docvars(tweetCorpus, field= "university")
class(docvars(tweetCorpus, field= "university"))
class(tweets)
class(tweetCorpus)
class(tweets$month)
class(tweets$university)
class(tweets$screen_name)
